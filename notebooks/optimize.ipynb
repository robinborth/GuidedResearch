{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import hydra\n",
    "from lib.utils.config import load_config\n",
    "from lib.model.flame import FLAME\n",
    "from lib.data.datamodule import DPHMDataModule\n",
    "from lib.data.scheduler import CoarseToFineScheduler, FinetuneScheduler\n",
    "from lib.model.flame import FLAME\n",
    "from lib.model.logger import FlameLogger\n",
    "from lib.model.loss import calculate_point2plane\n",
    "\n",
    "cfg = load_config(\n",
    "    \"optimize\",\n",
    "    overrides=[\n",
    "        \"optimizer=gauss_newton\",\n",
    "        \"optimzier.lin_solver.dim=6\",\n",
    "        \"joint_trainer.init_idxs=[0]\",\n",
    "        \"joint_trainer.max_iters=1\",\n",
    "        \"joint_trainer.max_optims=1\",\n",
    "        \"joint_trainer.scheduler.milestones=[0]\",\n",
    "        \"joint_trainer.scheduler.params=[[global_pose,transl]]\",\n",
    "        \"joint_trainer.coarse2fine.milestones=[0]\",\n",
    "        \"joint_trainer.coarse2fine.scales=[8]\",\n",
    "        \"sequential_trainer=null\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "K = load_intrinsics(data_dir=cfg.data.data_dir, return_tensor=\"pt\")\n",
    "camera = Camera(\n",
    "    K=K,\n",
    "    width=cfg.data.width,\n",
    "    height=cfg.data.height,\n",
    "    near=cfg.data.near,\n",
    "    far=cfg.data.far,\n",
    ")\n",
    "rasterizer = Rasterizer(width=camera.width, height=camera.height)\n",
    "datamodule: DPHMDataModule = hydra.utils.instantiate(cfg.data, devie=device)\n",
    "logger: FlameLogger = hydra.utils.instantiate(cfg.logger)\n",
    "model: FLAME = hydra.utils.instantiate(cfg.model).to(device)\n",
    "coarse2fine: FinetuneScheduler = hydra.utils.instantiate(cfg.scheduler.finetune)\n",
    "scheduler: CoarseToFineScheduler = hydra.utils.instantiate(cfg.scheduler.coarse2fine)\n",
    "\n",
    "datamodule.setup()\n",
    "model.init_renderer(camera=camera, rasterizer=rasterizer)\n",
    "coarse2fine.init_scheduler(camera=camera, rasterizer=rasterizer)\n",
    "model.init_logger(logger=logger)\n",
    "optimizer.init_logger(logger=logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch single batch\n",
    "iter_step = 0\n",
    "c2fs.schedule_dataset(datamodule=datamodule, iter_step=iter_step)\n",
    "fts.param_groups(model, iter_step=iter_step)\n",
    "dataloader = datamodule.train_dataloader()\n",
    "batch = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler.configure_optimizer(\n",
    "    optimizer=optimizer,\n",
    "    model=model,\n",
    "    batch=batch,\n",
    "    iter_step=iter_step,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "signature = inspect.signature(model.forward)\n",
    "param_names = [param.name for param in signature.parameters.values()]\n",
    "param_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# n = 100\n",
    "A = torch.rand((700, 700))\n",
    "B = torch.rand(700)\n",
    "X = torch.linalg.solve(A, B)\n",
    "x = torch.zeros((700), requires_grad=True)\n",
    "# def foo(x):\n",
    "#     return (A @ x - B)\n",
    "# J = torch.autograd.functional.jacobian(foo, x)\n",
    "# J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "inputs = torch.rand(2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd.functional import jacobian\n",
    "\n",
    "def exp_reducer(x):\n",
    "    return x.exp().sum(dim=1)\n",
    "# jacobian(exp_reducer, inputs, strategy=\"forward-mode\", vectorize=True)\n",
    "jacobian(exp_reducer, inputs, strategy=\"reverse-mode\", vectorize=True, create_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.rand(2, 2)\n",
    "inputs.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.func import jacrev, vmap, jacfwd\n",
    "def f(x):\n",
    "    return x.sin().sum(dim=-1)\n",
    "v = vmap(jacrev(torch.exp))(inputs)\n",
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jacobian(exp_reducer, inputs, strategy=\"forward-mode\", vectorize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "max_steps = 100000\n",
    "x = torch.zeros((n), requires_grad=True)\n",
    "# optimizer = torch.optim.Adam([x], lr=1.0) \n",
    "optimizer = torch.optim.LBFGS([x) \n",
    "\n",
    "for step in tqdm(range(max_steps)):\n",
    "    optimizer.zero_grad()\n",
    "    F = A @ x - B\n",
    "    loss = torch.pow(F, 2).sum()\n",
    "    # print(f\"{step}) {loss}\")\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "print(f\"{step}) {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A.inverse() @ B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(A.T @ A).inverse() @ (A.T @ B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.linalg.solve(A, B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.tensor([2., 3.], requires_grad=True)\n",
    "b = torch.tensor([6., 4.], requires_grad=True)\n",
    "Q = 3*a**3 - b**2\n",
    "external_grad = torch.tensor([1., 1.])\n",
    "Q.sum().backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn(5, requires_grad=True)\n",
    "b = 2 * a\n",
    "c = b ** 2  # replace this with c = b + 2 and the autograd error will go away\n",
    "print(b._version)\n",
    "b = b + 1\n",
    "print(b._version)\n",
    "b += 1  # inplace operation!\n",
    "print(b._version)\n",
    "# c.sum().backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "guided",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
