{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import hydra\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "from lib.utils.config import load_config\n",
    "from lib.optimizer.framework import NeuralOptimizer\n",
    "from lib.data.loader import load_intrinsics\n",
    "from lib.data.loader import load_intrinsics\n",
    "from lib.rasterizer import Rasterizer\n",
    "from lib.renderer.renderer import Renderer\n",
    "from lib.renderer.camera import Camera\n",
    "from lib.tracker.timer import TimeTracker\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def path_to_abblation(path):\n",
    "    return \"_\".join(path.split(\"/\")[-3].split(\"_\")[1:])\n",
    "\n",
    "\n",
    "def eval_iterations(optimizer, datamodule, N: int = 3):\n",
    "    optimizer.max_iters = N\n",
    "    optimizer.max_optims = 1\n",
    "    time_tracker = TimeTracker()\n",
    "    n_threshold =  optimizer.c_module.n_threshold\n",
    "    d_threshold = optimizer.c_module.d_threshold\n",
    "    # initial evaluation no optimization\n",
    "    p_loss = []\n",
    "    v_loss = []\n",
    "    g_loss = []\n",
    "    for batch in datamodule.val_dataloader():\n",
    "        with torch.no_grad():\n",
    "            batch = optimizer.transfer_batch_to_device(batch, \"cuda\", 0)\n",
    "            time_tracker.start(\"optimize\")\n",
    "            out = optimizer(batch)\n",
    "            time_tracker.stop(\"optimize\")\n",
    "            optimizer.c_module.n_threshold = -1.0\n",
    "            optimizer.c_module.d_threshold = 1e-02  # 1cm\n",
    "            loss_info = optimizer.compute_loss(batch=batch, out=out)\n",
    "            optimizer.c_module.n_threshold = n_threshold\n",
    "            optimizer.c_module.d_threshold = d_threshold  # 1cm\n",
    "            p_loss.append(loss_info[\"loss_param\"])\n",
    "            v_loss.append(loss_info[\"loss_vertices\"])\n",
    "            g_loss.append(loss_info[\"loss_geometric_point2point\"])\n",
    "    iters_p_loss = torch.stack(p_loss).mean().item()\n",
    "    iters_g_loss = torch.stack(g_loss).mean().item()\n",
    "    iters_v_loss = torch.stack(v_loss).mean().item()\n",
    "    t_perf = [torch.tensor(t.time_ms) for t in list(time_tracker.tracks.values())[0]]\n",
    "    iters_time = torch.stack(t_perf).min().item()\n",
    "    return iters_p_loss, iters_g_loss, iters_v_loss, iters_time\n",
    "\n",
    "\n",
    "def load_flame_renderer():\n",
    "    # instanciate similar to training\n",
    "    cfg = load_config(\"train\", [\"data=kinect\"])\n",
    "    K = load_intrinsics(data_dir=cfg.data.intrinsics_dir, return_tensor=\"pt\")\n",
    "    camera = Camera(\n",
    "        K=K,\n",
    "        width=cfg.data.width,\n",
    "        height=cfg.data.height,\n",
    "        near=cfg.data.near,\n",
    "        far=cfg.data.far,\n",
    "        scale=cfg.data.scale,\n",
    "    )\n",
    "    rasterizer = Rasterizer(width=camera.width, height=camera.height)\n",
    "    renderer = Renderer(rasterizer=rasterizer, camera=camera)\n",
    "    flame = hydra.utils.instantiate(cfg.model)\n",
    "    return flame, renderer\n",
    "\n",
    "\n",
    "def load_neural_optimizer(flame, renderer, path, override=[]):\n",
    "    o = [\"data=kinect\"] + override\n",
    "    cfg = load_config(\"train\", o)\n",
    "    correspondence = hydra.utils.instantiate(cfg.correspondence)\n",
    "    weighting = hydra.utils.instantiate(cfg.weighting)\n",
    "    residuals = hydra.utils.instantiate(cfg.residuals)\n",
    "    regularize = hydra.utils.instantiate(cfg.regularize)\n",
    "    neural_optimizer = NeuralOptimizer.load_from_checkpoint(\n",
    "        path,\n",
    "        renderer=renderer,\n",
    "        flame=flame,\n",
    "        correspondence=correspondence,\n",
    "        regularize=regularize,\n",
    "        residuals=residuals,\n",
    "        weighting=weighting,\n",
    "    )\n",
    "    return neural_optimizer\n",
    "\n",
    "\n",
    "def load_icp_optimizer(flame, renderer, overrides):\n",
    "    o = [\"data=kinect\", \"optimizer.output_dir=none\"] + overrides\n",
    "    cfg = load_config(\"train\", o)\n",
    "    correspondence = hydra.utils.instantiate(cfg.correspondence)\n",
    "    weighting = hydra.utils.instantiate(cfg.weighting)\n",
    "    residuals = hydra.utils.instantiate(cfg.residuals)\n",
    "    optimizer = hydra.utils.instantiate(cfg.optimizer)\n",
    "    regularize = hydra.utils.instantiate(cfg.regularize)\n",
    "    icp_optimizer = hydra.utils.instantiate(\n",
    "        cfg.framework,\n",
    "        flame=flame,\n",
    "        logger=None,\n",
    "        renderer=renderer,\n",
    "        correspondence=correspondence,\n",
    "        regularize=regularize,\n",
    "        residuals=residuals,\n",
    "        optimizer=optimizer,\n",
    "        weighting=weighting,\n",
    "    )\n",
    "    return icp_optimizer.to(\"cuda\")\n",
    "\n",
    "\n",
    "# setup the datamodule\n",
    "def load_datamodule(renderer, start_frame, end_frame, jump_size):\n",
    "    cfg = load_config(\"train\", [\"data=kinect\"])\n",
    "    datamodule = hydra.utils.instantiate(\n",
    "        cfg.data,\n",
    "        renderer=renderer,\n",
    "        val_dataset=dict(\n",
    "            start_frame=start_frame,\n",
    "            end_frame=end_frame,\n",
    "            jump_size=jump_size,\n",
    "        ),\n",
    "    )\n",
    "    datamodule.setup(\"fit\")\n",
    "    return datamodule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating GL context for cuda device 0\n",
      "Successfully initialized EGL version 1.5\n",
      "Successfully initialized OpenGL version 4.6.0 NVIDIA 535.183.01\n"
     ]
    }
   ],
   "source": [
    "N = 2\n",
    "step_size = 0.7\n",
    "start_frame = 48 \n",
    "end_frame = 56\n",
    "# start_frame = 30\n",
    "# end_frame = None\n",
    "\n",
    "# checkpoints\n",
    "ours = \"/home/borth/GuidedResearch/checkpoints/kinect/ours.ckpt\"\n",
    "ours_wo_prior = \"/home/borth/GuidedResearch/checkpoints/kinect/wo_prior.ckpt\"\n",
    "ours_syn = \"/home/borth/GuidedResearch/checkpoints/kinect/synthetic.ckpt\"\n",
    "\n",
    "# loadings\n",
    "times = defaultdict(dict)\n",
    "p_losses = defaultdict(dict)\n",
    "g_losses = defaultdict(dict)\n",
    "v_losses = defaultdict(dict)\n",
    "flame, renderer = load_flame_renderer()\n",
    "\n",
    "for jump_size in [1, 2, 4, 8]:\n",
    "    datamodule = load_datamodule(renderer, start_frame, end_frame, jump_size)\n",
    "\n",
    "    override = [\"residuals=face2face_wo_landmarks\", \"regularize=dummy\"]\n",
    "    optimizer = load_neural_optimizer(flame, renderer, ours_wo_prior, override)\n",
    "    optimizer.optimizer.step_size = step_size\n",
    "    p_loss, g_loss, v_loss, time = eval_iterations(optimizer, datamodule, N=N)\n",
    "    key = \"ours_wo_prior\"\n",
    "    times[key][jump_size] = time\n",
    "    p_losses[key][jump_size] = p_loss\n",
    "    v_losses[key][jump_size] = v_loss\n",
    "    g_losses[key][jump_size] = g_loss    \n",
    "\n",
    "    optimizer = load_neural_optimizer(flame, renderer, ours_syn, override)\n",
    "    optimizer.optimizer.step_size = step_size\n",
    "    p_loss, g_loss, v_loss, time = eval_iterations(optimizer, datamodule, N=N)\n",
    "    key = \"ours_syn\"\n",
    "    times[key][jump_size] = time\n",
    "    p_losses[key][jump_size] = p_loss\n",
    "    v_losses[key][jump_size] = v_loss\n",
    "    g_losses[key][jump_size] = g_loss\n",
    "\n",
    "    optimizer = load_neural_optimizer(flame, renderer, ours, [])\n",
    "    optimizer.optimizer.step_size = step_size\n",
    "    p_loss, g_loss, v_loss, time = eval_iterations(optimizer, datamodule, N=N)\n",
    "    key = \"ours\"\n",
    "    times[key][jump_size] = time\n",
    "    p_losses[key][jump_size] = p_loss\n",
    "    v_losses[key][jump_size] = v_loss\n",
    "    g_losses[key][jump_size] = g_loss\n",
    "\n",
    "    optimizer = load_icp_optimizer(flame, renderer, [])\n",
    "    optimizer.optimizer.step_size = 0.0\n",
    "    p_loss, g_loss, v_loss, time = eval_iterations(optimizer, datamodule, N=1)\n",
    "    key = \"base\"\n",
    "    times[key][jump_size] = time\n",
    "    p_losses[key][jump_size] = p_loss\n",
    "    v_losses[key][jump_size] = v_loss\n",
    "    g_losses[key][jump_size] = g_loss\n",
    "\n",
    "    optimizer = load_icp_optimizer(flame, renderer, [\"residuals=point2plane\", \"weighting=dummy\", \"regularize=dummy\"])\n",
    "    optimizer.optimizer.step_size = step_size\n",
    "    p_loss, g_loss, v_loss, time = eval_iterations(optimizer, datamodule, N=N)\n",
    "    key = \"icp-wo_reg\"\n",
    "    times[key][jump_size] = time\n",
    "    p_losses[key][jump_size] = p_loss\n",
    "    v_losses[key][jump_size] = v_loss\n",
    "    g_losses[key][jump_size] = g_loss\n",
    "\n",
    "    optimizer = load_icp_optimizer(flame, renderer, [\"residuals=face2face_wo_landmarks\", \"weighting=dummy\", \"regularize=dummy\"])\n",
    "    optimizer.optimizer.step_size = step_size\n",
    "    p_loss, g_loss, v_loss, time = eval_iterations(optimizer, datamodule, N=N)\n",
    "    key = \"icp-w_reg\"\n",
    "    times[key][jump_size] = time\n",
    "    p_losses[key][jump_size] = p_loss\n",
    "    v_losses[key][jump_size] = v_loss\n",
    "    g_losses[key][jump_size] = g_loss\n",
    "\n",
    "    optimizer = load_icp_optimizer(flame, renderer, [\"residuals=face2face_wo_landmarks\", \"weighting=dummy\", \"regularize=dummy\"])\n",
    "    optimizer.optimizer.step_size = 0.3\n",
    "    p_loss, g_loss, v_loss, time = eval_iterations(optimizer, datamodule, N=N)\n",
    "    key = \"icp-step\"\n",
    "    times[key][jump_size] = time\n",
    "    p_losses[key][jump_size] = p_loss\n",
    "    v_losses[key][jump_size] = v_loss\n",
    "    g_losses[key][jump_size] = g_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">FLAME (norm)</th>\n",
       "      <th colspan=\"4\" halign=\"left\">P2P (mm)</th>\n",
       "      <th colspan=\"4\" halign=\"left\">Vertices (mm)</th>\n",
       "      <th>Time (ms)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>0-&gt;1</th>\n",
       "      <th>0-&gt;2</th>\n",
       "      <th>0-&gt;4</th>\n",
       "      <th>0-&gt;8</th>\n",
       "      <th>0-&gt;1</th>\n",
       "      <th>0-&gt;2</th>\n",
       "      <th>0-&gt;4</th>\n",
       "      <th>0-&gt;8</th>\n",
       "      <th>0-&gt;1</th>\n",
       "      <th>0-&gt;2</th>\n",
       "      <th>0-&gt;4</th>\n",
       "      <th>0-&gt;8</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>base</th>\n",
       "      <td>0.323893</td>\n",
       "      <td>0.500221</td>\n",
       "      <td>0.599251</td>\n",
       "      <td>0.588814</td>\n",
       "      <td>1.963086</td>\n",
       "      <td>2.236378</td>\n",
       "      <td>2.534501</td>\n",
       "      <td>2.806092</td>\n",
       "      <td>6.464082</td>\n",
       "      <td>7.183959</td>\n",
       "      <td>8.352511</td>\n",
       "      <td>9.702329</td>\n",
       "      <td>25.291324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>icp-geo</th>\n",
       "      <td>1.894712</td>\n",
       "      <td>2.096590</td>\n",
       "      <td>2.485184</td>\n",
       "      <td>4.493804</td>\n",
       "      <td>1.654865</td>\n",
       "      <td>1.711433</td>\n",
       "      <td>1.777805</td>\n",
       "      <td>1.912375</td>\n",
       "      <td>6.540590</td>\n",
       "      <td>6.698123</td>\n",
       "      <td>7.235021</td>\n",
       "      <td>10.177958</td>\n",
       "      <td>42.121292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>icp-geo+reg</th>\n",
       "      <td>0.480108</td>\n",
       "      <td>0.517827</td>\n",
       "      <td>0.544179</td>\n",
       "      <td>0.581835</td>\n",
       "      <td>1.749189</td>\n",
       "      <td>1.763426</td>\n",
       "      <td>1.812692</td>\n",
       "      <td>1.924070</td>\n",
       "      <td>6.073561</td>\n",
       "      <td>6.093991</td>\n",
       "      <td>6.244667</td>\n",
       "      <td>8.344301</td>\n",
       "      <td>45.294762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>icp-geo+reg+step</th>\n",
       "      <td>0.342049</td>\n",
       "      <td>0.441612</td>\n",
       "      <td>0.506009</td>\n",
       "      <td>0.510001</td>\n",
       "      <td>1.795687</td>\n",
       "      <td>1.940052</td>\n",
       "      <td>2.138531</td>\n",
       "      <td>2.285906</td>\n",
       "      <td>6.114760</td>\n",
       "      <td>6.365917</td>\n",
       "      <td>6.991377</td>\n",
       "      <td>8.702782</td>\n",
       "      <td>44.856192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ours</th>\n",
       "      <td>0.317042</td>\n",
       "      <td>0.374115</td>\n",
       "      <td>0.437826</td>\n",
       "      <td>0.479327</td>\n",
       "      <td>1.674162</td>\n",
       "      <td>1.687540</td>\n",
       "      <td>1.746781</td>\n",
       "      <td>1.848207</td>\n",
       "      <td>6.087407</td>\n",
       "      <td>6.128869</td>\n",
       "      <td>6.344594</td>\n",
       "      <td>8.414172</td>\n",
       "      <td>50.575436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ours_w_prior</th>\n",
       "      <td>0.304566</td>\n",
       "      <td>0.414210</td>\n",
       "      <td>0.491348</td>\n",
       "      <td>0.493080</td>\n",
       "      <td>1.665385</td>\n",
       "      <td>1.696400</td>\n",
       "      <td>1.737456</td>\n",
       "      <td>1.856438</td>\n",
       "      <td>6.112013</td>\n",
       "      <td>6.141735</td>\n",
       "      <td>6.230826</td>\n",
       "      <td>7.806795</td>\n",
       "      <td>58.674574</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 FLAME (norm)                                P2P (mm)  \\\n",
       "                         0->1      0->2      0->4      0->8      0->1   \n",
       "base                 0.323893  0.500221  0.599251  0.588814  1.963086   \n",
       "icp-geo              1.894712  2.096590  2.485184  4.493804  1.654865   \n",
       "icp-geo+reg          0.480108  0.517827  0.544179  0.581835  1.749189   \n",
       "icp-geo+reg+step     0.342049  0.441612  0.506009  0.510001  1.795687   \n",
       "ours                 0.317042  0.374115  0.437826  0.479327  1.674162   \n",
       "ours_w_prior         0.304566  0.414210  0.491348  0.493080  1.665385   \n",
       "\n",
       "                                               Vertices (mm)            \\\n",
       "                      0->2      0->4      0->8          0->1      0->2   \n",
       "base              2.236378  2.534501  2.806092      6.464082  7.183959   \n",
       "icp-geo           1.711433  1.777805  1.912375      6.540590  6.698123   \n",
       "icp-geo+reg       1.763426  1.812692  1.924070      6.073561  6.093991   \n",
       "icp-geo+reg+step  1.940052  2.138531  2.285906      6.114760  6.365917   \n",
       "ours              1.687540  1.746781  1.848207      6.087407  6.128869   \n",
       "ours_w_prior      1.696400  1.737456  1.856438      6.112013  6.141735   \n",
       "\n",
       "                                       Time (ms)  \n",
       "                      0->4       0->8             \n",
       "base              8.352511   9.702329  25.291324  \n",
       "icp-geo           7.235021  10.177958  42.121292  \n",
       "icp-geo+reg       6.244667   8.344301  45.294762  \n",
       "icp-geo+reg+step  6.991377   8.702782  44.856192  \n",
       "ours              6.344594   8.414172  50.575436  \n",
       "ours_w_prior      6.230826   7.806795  58.674574  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desired_order = [\"base\", \"icp-w_reg\", \"icp-wo_reg\",\"icp-step\", \"ours\", \"ours_wo_prior\", \"ours_syn\"]\n",
    "\n",
    "# Create the DataFrame for p_losses\n",
    "p_losses_df = pd.DataFrame(p_losses).transpose()\n",
    "p_losses_df.columns = [f\"0->{c}\" for c in p_losses_df.columns]\n",
    "p_losses_df = p_losses_df.reindex(desired_order)\n",
    "p_losses_df.columns = pd.MultiIndex.from_tuples([(\"FLAME (norm)\", c) for c in p_losses_df.columns])\n",
    "\n",
    "# Create the DataFrame for g_losses\n",
    "g_losses_df = pd.DataFrame(g_losses).transpose()\n",
    "g_losses_df.columns = [f\"0->{c}\" for c in g_losses_df.columns]\n",
    "g_losses_df = g_losses_df.reindex(desired_order)\n",
    "g_losses_df.columns = pd.MultiIndex.from_tuples([(\"P2P (mm)\", c) for c in g_losses_df.columns])\n",
    "\n",
    "# Create the DataFrame for v_losses\n",
    "v_losses_df = pd.DataFrame(v_losses).transpose()\n",
    "v_losses_df.columns = [f\"0->{c}\" for c in v_losses_df.columns]\n",
    "v_losses_df = v_losses_df.reindex(desired_order)\n",
    "v_losses_df.columns = pd.MultiIndex.from_tuples([(\"Vertices (mm)\", c) for c in v_losses_df.columns])\n",
    "\n",
    "# Time\n",
    "time_df = pd.DataFrame(times).transpose()\n",
    "time_df = pd.DataFrame(time_df.mean(axis=1))\n",
    "time_df = time_df.reindex(desired_order)\n",
    "time_df.columns = pd.MultiIndex.from_tuples([(\"Time (ms)\", \"\")])\n",
    "\n",
    "# Concatenate the two DataFrames\n",
    "pd.concat([p_losses_df, g_losses_df, v_losses_df, time_df], axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "guided",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
