{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hydra\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "from lib.utils.config import load_config\n",
    "from lib.optimizer.framework import NeuralOptimizer\n",
    "from lib.data.loader import load_intrinsics\n",
    "from lib.data.loader import load_intrinsics\n",
    "from lib.rasterizer import Rasterizer\n",
    "from lib.renderer.renderer import Renderer\n",
    "from lib.renderer.camera import Camera\n",
    "from lib.tracker.timer import TimeTracker\n",
    "\n",
    "# settings\n",
    "N = 2\n",
    "value = \"loss_param\"\n",
    "path = \"/home/borth/GuidedResearch/logs/2024-10-01/15-13-21_train/checkpoints/epoch_029.ckpt\"\n",
    "start_frame = 10\n",
    "end_frame = 12\n",
    "\n",
    "# instanciate similar to training\n",
    "cfg = load_config(\"train\", [\"data=synthetic\"])\n",
    "K = load_intrinsics(data_dir=cfg.data.intrinsics_dir, return_tensor=\"pt\")\n",
    "camera = Camera(\n",
    "    K=K,\n",
    "    width=cfg.data.width,\n",
    "    height=cfg.data.height,\n",
    "    near=cfg.data.near,\n",
    "    far=cfg.data.far,\n",
    "    scale=cfg.data.scale,\n",
    ")\n",
    "rasterizer = Rasterizer(width=camera.width, height=camera.height)\n",
    "renderer = Renderer(rasterizer=rasterizer, camera=camera)\n",
    "flame = hydra.utils.instantiate(cfg.model)\n",
    "\n",
    "# setup the neural optimizer\n",
    "correspondence = hydra.utils.instantiate(cfg.correspondence)\n",
    "weighting = hydra.utils.instantiate(cfg.weighting)\n",
    "residuals = hydra.utils.instantiate(cfg.residuals)\n",
    "regularize = hydra.utils.instantiate(cfg.regularize)\n",
    "neural_optimizer = NeuralOptimizer.load_from_checkpoint(\n",
    "    path,\n",
    "    renderer=renderer,\n",
    "    flame=flame,\n",
    "    correspondence=correspondence,\n",
    "    regularize=regularize,\n",
    "    residuals=residuals,\n",
    "    weighting=weighting,\n",
    ")\n",
    "\n",
    "# setup icp optimizer\n",
    "cfg = load_config(\"train\", [\"data=synthetic\", \"residuals=face2face\", \"weighting=dummy\", \"regularize=dummy\",\"optimizer.output_dir=none\"])\n",
    "correspondence = hydra.utils.instantiate(cfg.correspondence)\n",
    "weighting = hydra.utils.instantiate(cfg.weighting)\n",
    "residuals = hydra.utils.instantiate(cfg.residuals)\n",
    "optimizer = hydra.utils.instantiate(cfg.optimizer)\n",
    "regularize = hydra.utils.instantiate(cfg.regularize)\n",
    "icp_optimizer = hydra.utils.instantiate(\n",
    "    cfg.framework,\n",
    "    flame=flame,\n",
    "    logger=None,\n",
    "    renderer=renderer,\n",
    "    correspondence=correspondence,\n",
    "    regularize=regularize,\n",
    "    residuals=residuals,\n",
    "    optimizer=optimizer,\n",
    "    weighting=weighting,\n",
    ")\n",
    "\n",
    "# setup the datamodule\n",
    "datamodule = hydra.utils.instantiate(\n",
    "    cfg.data,\n",
    "    renderer=renderer,\n",
    "    val_dataset=dict(\n",
    "        start_frame=start_frame,\n",
    "        end_frame=end_frame,\n",
    "    ),\n",
    ")\n",
    "datamodule.setup(\"fit\")\n",
    "dataloader = datamodule.val_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.utils.progress import reset_progress, close_progress\n",
    "\n",
    "def eval_iterations(optimizer, N: int = 1, value: str = \"loss_param\"):\n",
    "    outer_progress = tqdm(total=N+1, desc=\"Iter Loop\", position=0)\n",
    "    total_evals = len(datamodule.val_dataset)\n",
    "    inner_progress = tqdm(total=total_evals, desc=\"Eval Loop\", leave=True, position=1)\n",
    "    iters_loss = {}\n",
    "    iters_time = {}\n",
    "\n",
    "    # initial evaluation no optimization\n",
    "    reset_progress(inner_progress, total_evals)\n",
    "    loss = []\n",
    "    for batch in dataloader:\n",
    "        with torch.no_grad():\n",
    "            batch = optimizer.transfer_batch_to_device(batch, \"cuda\", 0)\n",
    "            out = optimizer(batch)\n",
    "            out[\"params\"] = batch[\"init_params\"]\n",
    "            loss_info = optimizer.compute_loss(batch=batch, out=out)\n",
    "            loss.append(loss_info[value])\n",
    "        inner_progress.update(1)\n",
    "    iters_loss[0] = torch.stack(loss)\n",
    "    iters_time[0] = torch.zeros_like(iters_loss[0])\n",
    "    outer_progress.update(1)\n",
    "        \n",
    "    # evaluation after some optimization\n",
    "    for iters in range(1, N+1):\n",
    "        reset_progress(inner_progress, total_evals)\n",
    "        optimizer.max_iters = iters\n",
    "        time_tracker = TimeTracker()\n",
    "        loss = []\n",
    "        for batch in dataloader:\n",
    "            with torch.no_grad():\n",
    "                batch = optimizer.transfer_batch_to_device(batch, \"cuda\", 0)\n",
    "                time_tracker.start(\"optimize\")\n",
    "                out = optimizer(batch)\n",
    "                time_tracker.stop(\"optimize\")\n",
    "                loss_info = optimizer.compute_loss(batch=batch, out=out)\n",
    "                loss.append(loss_info[value])\n",
    "            inner_progress.update(1)\n",
    "        loss = torch.stack(loss)\n",
    "        iters_loss[iters] = loss\n",
    "        iters_time[iters] = torch.stack([torch.tensor(t.time_ms) for t in list(time_tracker.tracks.values())[0]])\n",
    "        outer_progress.update(1)\n",
    "    close_progress([outer_progress, inner_progress])\n",
    "    return iters_loss, iters_time\n",
    "\n",
    "icp_loss, icp_time = eval_iterations(icp_optimizer, N=N, value=value) \n",
    "neural_loss, neural_time = eval_iterations(neural_optimizer, N=N, value=value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(neural_optimizer.time_tracker.print_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(icp_optimizer.time_tracker.print_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print({k: v.median() for k, v in neural_time.items()})\n",
    "print({k: v.median() for k, v in icp_time.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print({k: v.mean() for k, v in neural_loss.items()})\n",
    "print({k: v.mean() for k, v in icp_loss.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "icp_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "guided",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
