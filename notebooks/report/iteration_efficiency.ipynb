{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import hydra\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "from lib.utils.config import load_config\n",
    "from lib.optimizer.framework import NeuralOptimizer, NeuralOptimizer2\n",
    "from lib.data.loader import load_intrinsics\n",
    "from lib.data.loader import load_intrinsics\n",
    "from lib.rasterizer import Rasterizer\n",
    "from lib.renderer.renderer import Renderer\n",
    "from lib.renderer.camera import Camera\n",
    "from lib.tracker.timer import TimeTracker\n",
    "from lib.utils.progress import reset_progress, close_progress\n",
    "\n",
    "def path_to_abblation(path):\n",
    "    return \"_\".join(path.split(\"/\")[-3].split(\"_\")[1:])\n",
    "\n",
    "def eval_iterations(optimizer, datamodule, N: int = 1, value: str = \"loss_param\", mode=\"iters\"):\n",
    "    optimizer.max_iters = 1\n",
    "    optimizer.max_optims = 1\n",
    "\n",
    "    outer_progress = tqdm(total=N+1, desc=\"Iter Loop\", position=0)\n",
    "    total_evals = len(datamodule.val_dataset)\n",
    "    inner_progress = tqdm(total=total_evals, desc=\"Eval Loop\", leave=True, position=1)\n",
    "\n",
    "    iters_loss = {}\n",
    "    iters_time = {}\n",
    "\n",
    "    # initial evaluation no optimization\n",
    "    reset_progress(inner_progress, total_evals)\n",
    "    loss = []\n",
    "    for batch in datamodule.val_dataloader():\n",
    "        with torch.no_grad():\n",
    "            batch = optimizer.transfer_batch_to_device(batch, \"cuda\", 0)\n",
    "            out = optimizer(batch)\n",
    "            out[\"params\"] = batch[\"init_params\"]\n",
    "            loss_info = optimizer.compute_loss(batch=batch, out=out)\n",
    "            loss.append(loss_info[value])\n",
    "        inner_progress.update(1)\n",
    "    iters_loss[0] = torch.stack(loss)\n",
    "    iters_time[0] = torch.zeros_like(iters_loss[0])\n",
    "    outer_progress.update(1)\n",
    "        \n",
    "    # evaluation after some optimization\n",
    "    for iters in range(1, N+1):\n",
    "        reset_progress(inner_progress, total_evals)\n",
    "        if mode == \"iters\":\n",
    "            optimizer.max_iters = iters\n",
    "        else:\n",
    "            optimizer.max_optims = iters\n",
    "        time_tracker = TimeTracker()\n",
    "        loss = []\n",
    "        for batch in datamodule.val_dataloader():\n",
    "            with torch.no_grad():\n",
    "                batch = optimizer.transfer_batch_to_device(batch, \"cuda\", 0)\n",
    "                time_tracker.start(\"optimize\")\n",
    "                out = optimizer(batch)\n",
    "                time_tracker.stop(\"optimize\")\n",
    "                loss_info = optimizer.compute_loss(batch=batch, out=out)\n",
    "                loss.append(loss_info[value])\n",
    "            inner_progress.update(1)\n",
    "        loss = torch.stack(loss)\n",
    "        iters_loss[iters] = loss\n",
    "        iters_time[iters] = torch.stack([torch.tensor(t.time_ms) for t in list(time_tracker.tracks.values())[0]])\n",
    "        outer_progress.update(1)\n",
    "    close_progress([outer_progress, inner_progress])\n",
    "    return iters_loss, iters_time\n",
    "\n",
    "def load_flame_renderer():\n",
    "    # instanciate similar to training\n",
    "    cfg = load_config(\"train\", [\"data=synthetic\"])\n",
    "    K = load_intrinsics(data_dir=cfg.data.intrinsics_dir, return_tensor=\"pt\")\n",
    "    camera = Camera(\n",
    "        K=K,\n",
    "        width=cfg.data.width,\n",
    "        height=cfg.data.height,\n",
    "        near=cfg.data.near,\n",
    "        far=cfg.data.far,\n",
    "        scale=cfg.data.scale,\n",
    "    )\n",
    "    rasterizer = Rasterizer(width=camera.width, height=camera.height)\n",
    "    renderer = Renderer(rasterizer=rasterizer, camera=camera)\n",
    "    flame = hydra.utils.instantiate(cfg.model)\n",
    "    return flame, renderer\n",
    "\n",
    "\n",
    "def load_neural_optimizer(flame, renderer, path):\n",
    "    cfg = load_config(\"train\", [\"data=synthetic\"])\n",
    "    correspondence = hydra.utils.instantiate(cfg.correspondence)\n",
    "    weighting = hydra.utils.instantiate(cfg.weighting)\n",
    "    residuals = hydra.utils.instantiate(cfg.residuals)\n",
    "    regularize = hydra.utils.instantiate(cfg.regularize)\n",
    "    neural_optimizer = NeuralOptimizer.load_from_checkpoint(\n",
    "        path,\n",
    "        renderer=renderer,\n",
    "        flame=flame,\n",
    "        correspondence=correspondence,\n",
    "        regularize=regularize,\n",
    "        residuals=residuals,\n",
    "        weighting=weighting,\n",
    "    )\n",
    "    return neural_optimizer\n",
    "\n",
    "def load_icp_optimizer(flame, renderer, overrides, neural_optimizer2: bool = False):\n",
    "    cfg = load_config(\"train\", [\"data=synthetic\", \"optimizer.output_dir=none\"]+overrides)\n",
    "    correspondence = hydra.utils.instantiate(cfg.correspondence)\n",
    "    weighting = hydra.utils.instantiate(cfg.weighting)\n",
    "    residuals = hydra.utils.instantiate(cfg.residuals)\n",
    "    optimizer = hydra.utils.instantiate(cfg.optimizer)\n",
    "    regularize = hydra.utils.instantiate(cfg.regularize)\n",
    "    if neural_optimizer2:\n",
    "        cfg.framework._target_ = \"lib.optimizer.framework.NeuralOptimizer2\"\n",
    "    icp_optimizer = hydra.utils.instantiate(\n",
    "        cfg.framework,\n",
    "        flame=flame,\n",
    "        logger=None,\n",
    "        renderer=renderer,\n",
    "        correspondence=correspondence,\n",
    "        regularize=regularize,\n",
    "        residuals=residuals,\n",
    "        optimizer=optimizer,\n",
    "        weighting=weighting,\n",
    "    )\n",
    "    return icp_optimizer.to(\"cuda\")\n",
    "\n",
    "# setup the datamodule\n",
    "def load_datamodule(renderer, start_frame, end_frame):\n",
    "    cfg = load_config(\"train\", [\"data=synthetic\"])\n",
    "    datamodule = hydra.utils.instantiate(\n",
    "        cfg.data,\n",
    "        renderer=renderer,\n",
    "        val_dataset=dict(\n",
    "            start_frame=start_frame,\n",
    "            end_frame=end_frame,\n",
    "        ),\n",
    "    )\n",
    "    datamodule.setup(\"fit\")\n",
    "    return datamodule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating GL context for cuda device 0\n",
      "Successfully initialized EGL version 1.5\n",
      "Successfully initialized OpenGL version 4.6.0 NVIDIA 535.183.01\n"
     ]
    }
   ],
   "source": [
    "# settings\n",
    "N = 3\n",
    "value = \"loss_param\"  #  loss_vertices, loss_param \n",
    "start_frame = 10\n",
    "end_frame = 12\n",
    "\n",
    "# checkpoints\n",
    "ours = \"/home/borth/GuidedResearch/logs/2024-10-01/03-31-59_abblation_ours/checkpoints/last.ckpt\"\n",
    "wo_neural_prior = \"/home/borth/GuidedResearch/logs/2024-10-01/00-59-15_abblation_wo_neural_prior/checkpoints/last.ckpt\"\n",
    "w_single_corresp = \"/home/borth/GuidedResearch/logs/2024-10-01/22-07-11_abblation_w_single_corresp/checkpoints/last.ckpt\"\n",
    "w_single_optim = \"/home/borth/GuidedResearch/logs/2024-10-01/22-07-11_abblation_w_single_optim/checkpoints/last.ckpt\"\n",
    "wo_neural_weights = \"/home/borth/GuidedResearch/logs/2024-10-01/23-50-37_abblation_wo_neural_weights/checkpoints/last.ckpt\"\n",
    "\n",
    "# loadings\n",
    "times = {}\n",
    "losses = {}\n",
    "flame, renderer = load_flame_renderer()\n",
    "datamodule = load_datamodule(renderer, start_frame, end_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in [ours, wo_neural_prior, wo_neural_weights]:\n",
    "    optimizer = load_neural_optimizer(flame, renderer, path)\n",
    "    loss, time = eval_iterations(optimizer, datamodule, N=N, value=value, mode=\"iters\")\n",
    "    key = path_to_abblation(path)\n",
    "    times[key] = time[N].median().item()\n",
    "    losses[key] = loss[N].mean().item()\n",
    "    print(f\"{key}: loss={losses[key]:.03f} time={times[key]:.03f}ms\")\n",
    "\n",
    "path = w_single_corresp\n",
    "optimizer = load_neural_optimizer(flame, renderer, path)\n",
    "loss, time = eval_iterations(optimizer, datamodule, N=N, value=value, mode=\"optims\")\n",
    "key = path_to_abblation(path)\n",
    "times[key] = time[N].median().item()\n",
    "losses[key] = loss[N].mean().item()\n",
    "print(f\"{key}: loss={losses[key]:.03f} time={times[key]:.03f}ms\")\n",
    "\n",
    "path = w_single_optim \n",
    "optimizer = load_neural_optimizer(flame, renderer, path)\n",
    "loss, time = eval_iterations(optimizer, datamodule, N=N, value=value, mode=\"optims\")\n",
    "key = \"abblation_wo_end_to_end\"\n",
    "times[key] = time[N].median().item()\n",
    "losses[key] = loss[N].mean().item()\n",
    "print(f\"{key}: loss={losses[key]:.03f} time={times[key]:.03f}ms\")\n",
    "key = path_to_abblation(path)\n",
    "times[key] = time[1].median().item()\n",
    "losses[key] = loss[1].mean().item()\n",
    "print(f\"{key}: loss={losses[key]:.03f} time={times[key]:.03f}ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = load_icp_optimizer(flame, renderer, [\"residuals=face2face\", \"weighting=dummy\", \"regularize=dummy\"])\n",
    "loss, time = eval_iterations(optimizer, datamodule, N=N, value=value)\n",
    "print(\"icp-baseline\")\n",
    "print(optimizer.time_tracker.print_summary())\n",
    "print({k: v.median().item() for k, v in time.items()})\n",
    "print({k: v.mean().item() for k, v in loss.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = load_icp_optimizer(flame, renderer, [\"regularize.latent_scale=1\"])\n",
    "loss, time = eval_iterations(optimizer, datamodule, N=1, value=value)\n",
    "print(optimizer.time_tracker.print_summary())\n",
    "print({k: v.median().item() for k, v in time.items()})\n",
    "print({k: v.mean().item() for k, v in loss.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = load_icp_optimizer(flame, renderer, [\"weighting.features=64\"])\n",
    "loss, time = eval_iterations(optimizer, datamodule, N=1, value=value)\n",
    "print(optimizer.time_tracker.print_summary())\n",
    "print({k: v.median().item() for k, v in time.items()})\n",
    "print({k: v.mean().item() for k, v in loss.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b4569dcb4a8417d88ac210aa7d1bcc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iter Loop:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6084b5c7d2041d8ac87cb5aaf8d5d3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval Loop:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "Cannot access data pointer of Tensor that doesn't have storage",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m load_icp_optimizer(flame, renderer, [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mregularize.latent_scale=4\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m----> 2\u001b[0m loss, time \u001b[38;5;241m=\u001b[39m \u001b[43meval_iterations\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mN\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(optimizer\u001b[38;5;241m.\u001b[39mtime_tracker\u001b[38;5;241m.\u001b[39mprint_summary())\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m({k: v\u001b[38;5;241m.\u001b[39mmedian()\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m time\u001b[38;5;241m.\u001b[39mitems()})\n",
      "Cell \u001b[0;32mIn[1], line 34\u001b[0m, in \u001b[0;36meval_iterations\u001b[0;34m(optimizer, datamodule, N, value, mode)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m     33\u001b[0m     batch \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mtransfer_batch_to_device(batch, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 34\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43moptimizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m     out[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minit_params\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     36\u001b[0m     loss_info \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mcompute_loss(batch\u001b[38;5;241m=\u001b[39mbatch, out\u001b[38;5;241m=\u001b[39mout)\n",
      "File \u001b[0;32m~/miniconda3/envs/guided/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/guided/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/GuidedResearch/lib/optimizer/framework.py:508\u001b[0m, in \u001b[0;36mNeuralOptimizer2.forward\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    506\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime_tracker\u001b[38;5;241m.\u001b[39mstart(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minner_loop\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    507\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m optim_step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_optims):\n\u001b[0;32m--> 508\u001b[0m     optim_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresidual_closure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    509\u001b[0m     optim_outs\u001b[38;5;241m.\u001b[39mappend(optim_out)\n\u001b[1;32m    510\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime_tracker\u001b[38;5;241m.\u001b[39mstop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minner_loop\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/GuidedResearch/lib/optimizer/newton.py:122\u001b[0m, in \u001b[0;36mGaussNewton.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, closure: Callable[[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, torch\u001b[38;5;241m.\u001b[39mTensor]], torch\u001b[38;5;241m.\u001b[39mTensor]):\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# prepare the init delta vectors\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime_tracker\u001b[38;5;241m.\u001b[39mstart(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply_jacobian\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 122\u001b[0m     J, F, H, grad_f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_jacobian\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;66;03m# solve for the direction\u001b[39;00m\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime_tracker\u001b[38;5;241m.\u001b[39mstart(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msolve_delta\u001b[39m\u001b[38;5;124m\"\u001b[39m, stop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/GuidedResearch/lib/optimizer/newton.py:66\u001b[0m, in \u001b[0;36mNewtonOptimizer.apply_jacobian\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_jacobian\u001b[39m(\u001b[38;5;28mself\u001b[39m, closure: Callable[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, torch\u001b[38;5;241m.\u001b[39mTensor]):\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime_tracker\u001b[38;5;241m.\u001b[39mstart(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjacobian_closure\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 66\u001b[0m     J, F \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjacobian_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrategy\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# (M, N)\u001b[39;00m\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m J\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_numel\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime_tracker\u001b[38;5;241m.\u001b[39mstart(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mH\u001b[39m\u001b[38;5;124m\"\u001b[39m, stop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/GuidedResearch/lib/optimizer/base.py:210\u001b[0m, in \u001b[0;36mDifferentiableOptimizer.jacobian_step\u001b[0;34m(self, closure, strategy)\u001b[0m\n\u001b[1;32m    204\u001b[0m fn \u001b[38;5;241m=\u001b[39m jacfwd \u001b[38;5;28;01mif\u001b[39;00m strategy \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforward-mode\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m jacrev\n\u001b[1;32m    205\u001b[0m jacobian_fn \u001b[38;5;241m=\u001b[39m fn(\n\u001b[1;32m    206\u001b[0m     func\u001b[38;5;241m=\u001b[39mclosure,\n\u001b[1;32m    207\u001b[0m     argnums\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aktive_params))),\n\u001b[1;32m    208\u001b[0m     has_aux\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    209\u001b[0m )\n\u001b[0;32m--> 210\u001b[0m jacobians, (F, info) \u001b[38;5;241m=\u001b[39m \u001b[43mjacobian_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_aktive_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    211\u001b[0m J \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([j\u001b[38;5;241m.\u001b[39mflatten(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m jacobians], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# (M, N)\u001b[39;00m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresidual_tracker\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mint\u001b[39m(J\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]))\n",
      "File \u001b[0;32m~/miniconda3/envs/guided/lib/python3.10/site-packages/torch/_functorch/eager_transforms.py:1163\u001b[0m, in \u001b[0;36mjacfwd.<locals>.wrapper_fn\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   1160\u001b[0m     _, jvp_out \u001b[38;5;241m=\u001b[39m output\n\u001b[1;32m   1161\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m jvp_out\n\u001b[0;32m-> 1163\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mvmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpush_jvp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandomness\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrandomness\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbasis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1164\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_aux:\n\u001b[1;32m   1165\u001b[0m     results, aux \u001b[38;5;241m=\u001b[39m results\n",
      "File \u001b[0;32m~/miniconda3/envs/guided/lib/python3.10/site-packages/torch/_functorch/apis.py:188\u001b[0m, in \u001b[0;36mvmap.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 188\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mvmap_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandomness\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/guided/lib/python3.10/site-packages/torch/_functorch/vmap.py:281\u001b[0m, in \u001b[0;36mvmap_impl\u001b[0;34m(func, in_dims, out_dims, randomness, chunk_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _chunked_vmap(func, flat_in_dims, chunks_flat_args,\n\u001b[1;32m    278\u001b[0m                          args_spec, out_dims, randomness, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    280\u001b[0m \u001b[38;5;66;03m# If chunk_size is not specified.\u001b[39;00m\n\u001b[0;32m--> 281\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_flat_vmap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflat_in_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs_spec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandomness\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/guided/lib/python3.10/site-packages/torch/_functorch/vmap.py:47\u001b[0m, in \u001b[0;36mdoesnt_support_saved_tensors_hooks.<locals>.fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(f)\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfn\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39mdisable_saved_tensors_hooks(message):\n\u001b[0;32m---> 47\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/guided/lib/python3.10/site-packages/torch/_functorch/vmap.py:403\u001b[0m, in \u001b[0;36m_flat_vmap\u001b[0;34m(func, batch_size, flat_in_dims, flat_args, args_spec, out_dims, randomness, **kwargs)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m vmap_increment_nesting(batch_size, randomness) \u001b[38;5;28;01mas\u001b[39;00m vmap_level:\n\u001b[1;32m    402\u001b[0m     batched_inputs \u001b[38;5;241m=\u001b[39m _create_batched_inputs(flat_in_dims, flat_args, vmap_level, args_spec)\n\u001b[0;32m--> 403\u001b[0m     batched_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbatched_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    404\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _unwrap_batched(batched_outputs, out_dims, vmap_level, batch_size, func)\n",
      "File \u001b[0;32m~/miniconda3/envs/guided/lib/python3.10/site-packages/torch/_functorch/eager_transforms.py:1154\u001b[0m, in \u001b[0;36mjacfwd.<locals>.wrapper_fn.<locals>.push_jvp\u001b[0;34m(basis)\u001b[0m\n\u001b[1;32m   1153\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpush_jvp\u001b[39m(basis):\n\u001b[0;32m-> 1154\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43m_jvp_with_argnums\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbasis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margnums\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margnums\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhas_aux\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_aux\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1155\u001b[0m     \u001b[38;5;66;03m# output[0] is the output of `func(*args)`\u001b[39;00m\n\u001b[1;32m   1156\u001b[0m     error_if_complex(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjacfwd\u001b[39m\u001b[38;5;124m\"\u001b[39m, output[\u001b[38;5;241m0\u001b[39m], is_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/guided/lib/python3.10/site-packages/torch/_functorch/vmap.py:47\u001b[0m, in \u001b[0;36mdoesnt_support_saved_tensors_hooks.<locals>.fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(f)\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfn\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39mdisable_saved_tensors_hooks(message):\n\u001b[0;32m---> 47\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/guided/lib/python3.10/site-packages/torch/_functorch/eager_transforms.py:1000\u001b[0m, in \u001b[0;36m_jvp_with_argnums\u001b[0;34m(func, primals, tangents, argnums, strict, has_aux)\u001b[0m\n\u001b[1;32m    998\u001b[0m     primals \u001b[38;5;241m=\u001b[39m _wrap_all_tensors(primals, level)\n\u001b[1;32m    999\u001b[0m     duals \u001b[38;5;241m=\u001b[39m _replace_args(primals, duals, argnums)\n\u001b[0;32m-> 1000\u001b[0m result_duals \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mduals\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1001\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_aux:\n\u001b[1;32m   1002\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(result_duals, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(result_duals) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m):\n",
      "File \u001b[0;32m~/GuidedResearch/lib/optimizer/framework.py:456\u001b[0m, in \u001b[0;36mNeuralOptimizer2.forward.<locals>.residual_closure\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    454\u001b[0m \u001b[38;5;66;03m# render the current state of the model\u001b[39;00m\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime_tracker\u001b[38;5;241m.\u001b[39mstart(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcorrespondences\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 456\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflame\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrenderer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    458\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[38;5;66;03m# establish correspondences\u001b[39;00m\n\u001b[1;32m    461\u001b[0m mask, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mc_module\u001b[38;5;241m.\u001b[39mmask(\n\u001b[1;32m    462\u001b[0m     s_mask\u001b[38;5;241m=\u001b[39mbatch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmask\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    463\u001b[0m     s_point\u001b[38;5;241m=\u001b[39mbatch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpoint\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    467\u001b[0m     t_normal\u001b[38;5;241m=\u001b[39mout[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnormal\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    468\u001b[0m )\n",
      "File \u001b[0;32m~/GuidedResearch/lib/model/flame/flame.py:271\u001b[0m, in \u001b[0;36mFlame.render\u001b[0;34m(self, renderer, params, vertices_mask)\u001b[0m\n\u001b[1;32m    269\u001b[0m     vertices_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvertices_mask\n\u001b[1;32m    270\u001b[0m faces \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mface_faces \u001b[38;5;28;01mif\u001b[39;00m vertices_mask \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mface\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfull_faces\n\u001b[0;32m--> 271\u001b[0m r_out \u001b[38;5;241m=\u001b[39m \u001b[43mrenderer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender_full\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvertices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mm_out\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvertices\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# (B, V, 3)\u001b[39;49;00m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfaces\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfaces\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# (F, 3)\u001b[39;49;00m\n\u001b[1;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    275\u001b[0m r_out\u001b[38;5;241m.\u001b[39mupdate(m_out)\n\u001b[1;32m    276\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m r_out\n",
      "File \u001b[0;32m~/GuidedResearch/lib/renderer/renderer.py:236\u001b[0m, in \u001b[0;36mRenderer.render_full\u001b[0;34m(self, vertices, faces)\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[38;5;66;03m# rasterize one time\u001b[39;00m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime_tracker\u001b[38;5;241m.\u001b[39mstart(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrasterize\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 236\u001b[0m fragments \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrasterize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvertices\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfaces\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;66;03m# depth based\u001b[39;00m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime_tracker\u001b[38;5;241m.\u001b[39mstart(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdepth_based\u001b[39m\u001b[38;5;124m\"\u001b[39m, stop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/GuidedResearch/lib/renderer/renderer.py:60\u001b[0m, in \u001b[0;36mRenderer.rasterize\u001b[0;34m(self, vertices, faces)\u001b[0m\n\u001b[1;32m     58\u001b[0m homo_vertices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcamera\u001b[38;5;241m.\u001b[39mconvert_to_homo_coords(vertices)\n\u001b[1;32m     59\u001b[0m homo_clip_vertices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcamera\u001b[38;5;241m.\u001b[39mclip_transform(homo_vertices)  \u001b[38;5;66;03m# (B, V, 4)\u001b[39;00m\n\u001b[0;32m---> 60\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrasterizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrasterize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhomo_clip_vertices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfaces\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/GuidedResearch/lib/rasterizer/torch_bindings.py:76\u001b[0m, in \u001b[0;36mRasterizer.rasterize\u001b[0;34m(self, vertices, indices)\u001b[0m\n\u001b[1;32m     74\u001b[0m _pix_to_face: \u001b[38;5;28mlist\u001b[39m[torch\u001b[38;5;241m.\u001b[39mTensor] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _vertices \u001b[38;5;129;01min\u001b[39;00m vertices:\n\u001b[0;32m---> 76\u001b[0m     f \u001b[38;5;241m=\u001b[39m \u001b[43mplugin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrasterize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mglctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_vertices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(f\u001b[38;5;241m.\u001b[39mbary_coords\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m  \u001b[38;5;66;03m# (H, W, 3)\u001b[39;00m\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(f\u001b[38;5;241m.\u001b[39mpix_to_face\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m  \u001b[38;5;66;03m# (H, W)\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Cannot access data pointer of Tensor that doesn't have storage"
     ]
    }
   ],
   "source": [
    "optimizer = load_icp_optimizer(flame, renderer, [\"regularize.latent_scale=4\"], True)\n",
    "loss, time = eval_iterations(optimizer, datamodule, N=1, value=value)\n",
    "print(optimizer.time_tracker.print_summary())\n",
    "print({k: v.median().item() for k, v in time.items()})\n",
    "print({k: v.mean().item() for k, v in loss.items()})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "guided",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
