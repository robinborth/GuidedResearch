{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(28.0144) tensor(0.0009)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from lib.optimizer.pcg import conjugate_gradient\n",
    "\n",
    "N = 100\n",
    "_A = torch.rand((N, N))\n",
    "A = torch.sqrt(_A.T @ _A) # positive semidefinite and symmetric\n",
    "b = torch.rand((N))\n",
    "x_pcg  = conjugate_gradient(A, b, verbose=True, max_iter=100)\n",
    "x_optim= torch.linalg.solve(A, b) \n",
    "pcg_norm = ((A @ x_pcg) - b).norm()\n",
    "optim_norm  = ((A @ x_optim) - b).norm()\n",
    "print(pcg_norm, optim_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9999/10000: 100%|██████████| 10000/10000 [00:31<00:00, 312.71it/s, loss=7.88e-5] \n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from lib.optimizer.pcg import PCGLayer\n",
    "from lib.optimizer.pcg import conjugate_gradient\n",
    "from torch.optim import Adam, SGD\n",
    "import torch\n",
    "\n",
    "# define the matrixes\n",
    "\n",
    "def generate_data(N, x_eps= 1e-02, a_eps=1e-01):\n",
    "    E = torch.rand((N, N)) * a_eps\n",
    "    A = torch.eye(N) + (E.T @ E) \n",
    "    x_gt = torch.rand((N))  * x_eps\n",
    "    b = A @ x_gt\n",
    "    return A, b, x_gt\n",
    "\n",
    "def eval_loss(x_pcg, x_gt, verbose=True):\n",
    "    l_pcg = (x_pcg-x_gt).norm()\n",
    "    if verbose:\n",
    "        print(\"Loss:\", l_pcg.item())\n",
    "    return l_pcg\n",
    "\n",
    "torch.manual_seed(42)\n",
    "N = 6\n",
    "# A, b, x_gt = generate_data(N)\n",
    "max_steps = 10000\n",
    "lr = 1e-05\n",
    "max_iter=2\n",
    "verbose=True\n",
    "tol=1e-08\n",
    "\n",
    "pcg = PCGLayer(N=N, max_iter=max_iter, verbose=verbose, tol=tol)\n",
    "optimizer = SGD(pcg.parameters(), lr=lr, momentum=0.90)\n",
    "# optimizer = Adam([M], lr=lr)\n",
    "\n",
    "for step in (pbar:=tqdm(range(max_steps), total=max_steps)):\n",
    "    pbar.set_description(f\"{step}/{max_steps}\")\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "  \n",
    "    A, b, x_gt = generate_data(N)\n",
    "    x = pcg(A, b)\n",
    "    loss = eval_loss(x, x_gt, verbose=False) \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    pbar.set_postfix({\"loss\": loss.item()})\n",
    "    pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.00019666290609166026\n",
      "Loss: 0.00032913850736804307\n"
     ]
    }
   ],
   "source": [
    "from lib.optimizer.pcg import preconditioned_conjugate_gradient\n",
    "A, b, x_gt = generate_data(N)\n",
    "x_cg = preconditioned_conjugate_gradient(A, b, max_iter=2)\n",
    "pcg.max_iter=2\n",
    "x = pcg(A, b)\n",
    "loss = eval_loss(x, x_gt, verbose=True) \n",
    "loss = eval_loss(x_cg, x_gt, verbose=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(p.size() for p in pcg.condition_net.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0002)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lib.optimizer.pcg import conjugate_gradient\n",
    "torch.manual_seed(42)\n",
    "N = 100\n",
    "E = torch.rand((N, N)) * 1e-02\n",
    "A= torch.eye(N) + (E.T @ E)\n",
    "x = torch.rand((N))  * 1e-02\n",
    "b = A @ x\n",
    "\n",
    "x_pcg = conjugate_gradient(A, b, max_iter=1)\n",
    "r_pcg = (A @ x_pcg - b).mean()\n",
    "r_pcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 5\n",
    "tri_N = ((N * N - N) // 2) + N\n",
    "L = torch.zeros((N, N))\n",
    "tril_indices = torch.tril_indices(row=N, col=N, offset=0)\n",
    "L[tril_indices[0], tril_indices[1]] = torch.rand(tri_N)\n",
    "L[4, 0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7.4866,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [-2.4248,  1.2898,  0.0000,  0.0000,  0.0000],\n",
       "        [-2.3654, -0.3140,  1.5110,  0.0000,  0.0000],\n",
       "        [-1.4245, -0.5119, -0.8082,  1.0566,  0.0000],\n",
       "        [ 0.9208,  0.1157, -0.1496, -0.2252,  1.4043]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L.inverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "\n",
    "\n",
    "def cg_batch(A_bmm, B, M_bmm=None, X0=None, rtol=1e-3, atol=0., maxiter=None, verbose=False):\n",
    "    \"\"\"Solves a batch of PD matrix linear systems using the preconditioned CG algorithm.\n",
    "\n",
    "    This function solves a batch of matrix linear systems of the form\n",
    "\n",
    "        A_i X_i = B_i,  i=1,...,K,\n",
    "\n",
    "    where A_i is a n x n positive definite matrix and B_i is a n x m matrix,\n",
    "    and X_i is the n x m matrix representing the solution for the ith system.\n",
    "\n",
    "    Args:\n",
    "        A_bmm: A callable that performs a batch matrix multiply of A and a K x n x m matrix.\n",
    "        B: A K x n x m matrix representing the right hand sides.\n",
    "        M_bmm: (optional) A callable that performs a batch matrix multiply of the preconditioning\n",
    "            matrices M and a K x n x m matrix. (default=identity matrix)\n",
    "        X0: (optional) Initial guess for X, defaults to M_bmm(B). (default=None)\n",
    "        rtol: (optional) Relative tolerance for norm of residual. (default=1e-3)\n",
    "        atol: (optional) Absolute tolerance for norm of residual. (default=0)\n",
    "        maxiter: (optional) Maximum number of iterations to perform. (default=5*n)\n",
    "        verbose: (optional) Whether or not to print status messages. (default=False)\n",
    "    \"\"\"\n",
    "    K, n, m = B.shape\n",
    "\n",
    "    if M_bmm is None:\n",
    "        M_bmm = lambda x: x\n",
    "    if X0 is None:\n",
    "        X0 = M_bmm(B)\n",
    "    if maxiter is None:\n",
    "        maxiter = 5 * n\n",
    "\n",
    "    assert B.shape == (K, n, m)\n",
    "    assert X0.shape == (K, n, m)\n",
    "    assert rtol > 0 or atol > 0\n",
    "    assert isinstance(maxiter, int)\n",
    "\n",
    "    X_k = X0\n",
    "    R_k = B - A_bmm(X_k)\n",
    "    Z_k = M_bmm(R_k)\n",
    "\n",
    "    P_k = torch.zeros_like(Z_k)\n",
    "\n",
    "    P_k1 = P_k\n",
    "    R_k1 = R_k\n",
    "    R_k2 = R_k\n",
    "    X_k1 = X0\n",
    "    Z_k1 = Z_k\n",
    "    Z_k2 = Z_k\n",
    "\n",
    "    B_norm = torch.norm(B, dim=1)\n",
    "    stopping_matrix = torch.max(rtol*B_norm, atol*torch.ones_like(B_norm))\n",
    "\n",
    "    if verbose:\n",
    "        print(\"%03s | %010s %06s\" % (\"it\", \"dist\", \"it/s\"))\n",
    "\n",
    "    optimal = False\n",
    "    start = time.perf_counter()\n",
    "    for k in range(1, maxiter + 1):\n",
    "        start_iter = time.perf_counter()\n",
    "        Z_k = M_bmm(R_k)\n",
    "\n",
    "        if k == 1:\n",
    "            P_k = Z_k\n",
    "            R_k1 = R_k\n",
    "            X_k1 = X_k\n",
    "            Z_k1 = Z_k\n",
    "        else:\n",
    "            R_k2 = R_k1\n",
    "            Z_k2 = Z_k1\n",
    "            P_k1 = P_k\n",
    "            R_k1 = R_k\n",
    "            Z_k1 = Z_k\n",
    "            X_k1 = X_k\n",
    "            denominator = (R_k2 * Z_k2).sum(1)\n",
    "            denominator[denominator == 0] = 1e-8\n",
    "            beta = (R_k1 * Z_k1).sum(1) / denominator\n",
    "            P_k = Z_k1 + beta.unsqueeze(1) * P_k1\n",
    "\n",
    "        denominator = (P_k * A_bmm(P_k)).sum(1)\n",
    "        denominator[denominator == 0] = 1e-8\n",
    "        alpha = (R_k1 * Z_k1).sum(1) / denominator\n",
    "        X_k = X_k1 + alpha.unsqueeze(1) * P_k\n",
    "        R_k = R_k1 - alpha.unsqueeze(1) * A_bmm(P_k)\n",
    "        end_iter = time.perf_counter()\n",
    "\n",
    "        residual_norm = torch.norm(A_bmm(X_k) - B, dim=1)\n",
    "\n",
    "        if verbose:\n",
    "            print(\"%03d | %8.4e %4.2f\" %\n",
    "                  (k, torch.max(residual_norm-stopping_matrix),\n",
    "                    1. / (end_iter - start_iter)))\n",
    "\n",
    "        if (residual_norm <= stopping_matrix).all():\n",
    "            optimal = True\n",
    "            break\n",
    "\n",
    "    end = time.perf_counter()\n",
    "\n",
    "    if verbose:\n",
    "        if optimal:\n",
    "            print(\"Terminated in %d steps (reached maxiter). Took %.3f ms.\" %\n",
    "                  (k, (end - start) * 1000))\n",
    "        else:\n",
    "            print(\"Terminated in %d steps (optimal). Took %.3f ms.\" %\n",
    "                  (k, (end - start) * 1000))\n",
    "\n",
    "\n",
    "    info = {\n",
    "        \"niter\": k,\n",
    "        \"optimal\": optimal\n",
    "    }\n",
    "\n",
    "    return X_k, info\n",
    "\n",
    "\n",
    "A = torch.tensor([[4.0,1],[1, 3]])[None, ...]\n",
    "def A_bmm(X):\n",
    "    Y = [(A[i]@X[i]).unsqueeze(0) for i in range(1)]\n",
    "    return torch.cat(Y, dim=0)\n",
    "b = torch.tensor([1.0,2])[None, ...][..., None]\n",
    "cg_batch(A_bmm=A_bmm, B=b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 100\n",
    "_A = torch.rand((N, N))\n",
    "z = torch.zeros_like(_A)\n",
    "for idx in range(70):\n",
    "    i = idx * 10\n",
    "    j = (idx+1)*10\n",
    "    z[i:j, i:j] = 1.0\n",
    "_A *= z\n",
    "A = torch.sqrt(_A.T @ _A) # positive and symetric\n",
    "# A = torch.diag(torch.diag(A))\n",
    "b = torch.rand((N)) + 2\n",
    "def A_bmm(X):\n",
    "    Y = [(A[None, ...][i]@X[i]).unsqueeze(0) for i in range(1)]\n",
    "    return torch.cat(Y, dim=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "s = time.time()\n",
    "out = cg_batch(A_bmm=A_bmm, B=b[None, ...][..., None], maxiter=10)\n",
    "print(time.time() - s)\n",
    "x_pcg = out[0].squeeze()\n",
    "s = time.time()\n",
    "x_optim = torch.linalg.solve(A, b)\n",
    "print(time.time() - s)\n",
    "pcg_norm = ((A @ x_pcg) - b).norm()\n",
    "optim_norm = ((A @ x_optim) - b).norm()\n",
    "pcg_norm, optim_norm, b.norm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "guided",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
