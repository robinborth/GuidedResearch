{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd.functional import jacobian\n",
    "from torch.func import jacrev, vmap, jacfwd\n",
    "from lib.trainer.timer import TimeTracker\n",
    "from lib.model.common import MLP\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = \"cuda\"\n",
    "steps = 10\n",
    "n_unknowns = 159\n",
    "n_residuals = 1135\n",
    "hidden_dim = 1000\n",
    "num_layers = 8\n",
    "\n",
    "\n",
    "tracker = TimeTracker()\n",
    "\n",
    "params = torch.randn((n_unknowns), requires_grad=True, device=device)\n",
    "params_no_grad = torch.randn((n_unknowns), requires_grad=False, device=device)\n",
    "mlp = MLP(\n",
    "    in_dim=n_unknowns,\n",
    "    out_dim=n_residuals,\n",
    "    hidden_dim=hidden_dim,\n",
    "    num_layers=num_layers,\n",
    ").to(device)\n",
    "print(\"MLP sum params:\", sum(p.numel() for p in mlp.parameters()))\n",
    "\n",
    "\n",
    "def f(x):\n",
    "    residuals = mlp(x)\n",
    "    return residuals\n",
    "\n",
    "\n",
    "def f_no_grad(x):\n",
    "    with torch.no_grad():\n",
    "        residuals = mlp(x)\n",
    "    return residuals\n",
    "\n",
    "\n",
    "for _ in tqdm(range(steps)):\n",
    "    tracker.start(\"reverse_jacobian_vectorize_graph\")\n",
    "    jacobian(f, params, strategy=\"reverse-mode\", vectorize=True, create_graph=True)\n",
    "    tracker.start(\"reverse_jacobian_vectorize\", stop=True)\n",
    "    jacobian(f, params, strategy=\"reverse-mode\", vectorize=True, create_graph=False)\n",
    "    tracker.start(\"reverse_jacobian_graph\", stop=True)\n",
    "    jacobian(f, params, strategy=\"reverse-mode\", vectorize=False, create_graph=True)\n",
    "    tracker.start(\"reverse_jacobian\", stop=True)\n",
    "    jacobian(f, params, strategy=\"reverse-mode\", vectorize=False, create_graph=False)\n",
    "    tracker.start(\"forward_jacobian_vectorize\", stop=True)\n",
    "    jacobian(f, params, strategy=\"forward-mode\", vectorize=True, create_graph=False)\n",
    "    tracker.start(\"reverse_vmapjac\", stop=True)\n",
    "    vmap(jacrev(f))(params.unsqueeze(0))[0]\n",
    "    tracker.start(\"reverse_jac\", stop=True)\n",
    "    jacrev(f)(params)\n",
    "    tracker.start(\"reverse_jac_chunk10\", stop=True)\n",
    "    jacrev(f, chunk_size=10)(params)\n",
    "    tracker.start(\"reverse_jac_chunk1000\", stop=True)\n",
    "    jacrev(f, chunk_size=1000)(params)\n",
    "    tracker.start(\"reverse_jac_chunk10000\", stop=True)\n",
    "    jacrev(f, chunk_size=10000)(params)\n",
    "    tracker.start(\"reverse_jac_chunk100000\", stop=True)\n",
    "    jacrev(f, chunk_size=100000)(params)\n",
    "    tracker.start(\"reverse_jac_no_grad\", stop=True)\n",
    "    jacrev(f_no_grad)(params)\n",
    "    tracker.start(\"forward_jac\", stop=True)\n",
    "    jacfwd(f)(params)\n",
    "    tracker.start(\"forward_jac_no_grad\", stop=True)\n",
    "    jacfwd(f_no_grad)(params)\n",
    "    tracker.start(\"forward_jac_no_grad\", stop=True)\n",
    "    jacfwd(f_no_grad)(params)\n",
    "    tracker.stop()\n",
    "\n",
    "print(tracker.print_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_comp(x):\n",
    "    residuals = mlp(x)\n",
    "    return residuals\n",
    "\n",
    "\n",
    "@torch.compile\n",
    "def jac():\n",
    "    jacrev(f_comp)(params)\n",
    "\n",
    "\n",
    "tracker = TimeTracker()\n",
    "\n",
    "for _ in tqdm(range(steps)):\n",
    "    tracker.start(\"reverse_jac\")\n",
    "    jac()\n",
    "    tracker.stop()\n",
    "\n",
    "print(tracker.print_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jacrev(f)(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jacfwd(f)(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FLAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.model.flame.flame import Flame\n",
    "import torch\n",
    "import hydra\n",
    "from lib.utils.config import load_config\n",
    "from lib.data.datamodule import DPHMDataModule\n",
    "from lib.trainer.logger import FlameLogger\n",
    "from lib.data.loader import load_intrinsics\n",
    "from lib.rasterizer import Rasterizer\n",
    "from lib.renderer.renderer import Renderer\n",
    "from lib.renderer.camera import Camera\n",
    "from lib.utils.config import set_configs\n",
    "from lib.optimizer.newton import GaussNewton\n",
    "from lib.optimizer.pcg import PytorchSolver\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data_dir = \"/home/borth/GuidedResearch/data/dphm_christoph_mouthmove\"\n",
    "flame_dir = \"/home/borth/GuidedResearch/checkpoints/flame2023\"\n",
    "\n",
    "cfg = load_config(\n",
    "    \"optimize\",\n",
    "    overrides=[\n",
    "        \"optimizer=gauss_newton\",\n",
    "        \"joint_trainer.init_idxs=[0]\",\n",
    "        \"joint_trainer.max_iters=1\",\n",
    "        \"joint_trainer.max_optims=1\",\n",
    "        \"joint_trainer.scheduler.milestones=[0]\",\n",
    "        \"joint_trainer.scheduler.params=[[global_pose,transl]]\",\n",
    "        \"joint_trainer.coarse2fine.milestones=[0]\",\n",
    "        \"joint_trainer.coarse2fine.scales=[8]\",\n",
    "        \"sequential_trainer=null\",\n",
    "    ],\n",
    ")\n",
    "cfg = set_configs(cfg)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# setup camera, rasterizer and renderer\n",
    "K = load_intrinsics(data_dir=cfg.data.data_dir, return_tensor=\"pt\")\n",
    "camera = Camera(\n",
    "    K=K,\n",
    "    width=cfg.data.width,\n",
    "    height=cfg.data.height,\n",
    "    near=cfg.data.near,\n",
    "    far=cfg.data.far,\n",
    "    scale=4,\n",
    ")\n",
    "\n",
    "rasterizer = Rasterizer(width=camera.width, height=camera.height)\n",
    "renderer = Renderer(rasterizer=rasterizer, camera=camera)\n",
    "\n",
    "# setup flame model\n",
    "flame = Flame(flame_dir=flame_dir, vertices_mask=\"full\", expression_params=50)\n",
    "\n",
    "# datamodule fetch batch\n",
    "datamodule = hydra.utils.instantiate(cfg.data, devie=device)\n",
    "datamodule.update_dataset(camera=camera, rasterizer=rasterizer)\n",
    "datamodule.update_idxs([0,1])\n",
    "batch = datamodule.fetch()\n",
    "\n",
    "\n",
    "params = {}\n",
    "params[\"shape_params\"] = torch.nn.Parameter(torch.zeros(2,100)).to(device)\n",
    "params[\"expression_params\"] = torch.nn.Parameter(torch.zeros(2,50)).to(device)\n",
    "params[\"global_pose\"] = torch.nn.Parameter(torch.tensor([[0.08, -0.24, -0.02],[0.08, -0.24, -0.02]])).to(device)\n",
    "params[\"neck_pose\"] = torch.nn.Parameter(torch.zeros(2,3)).to(device)\n",
    "params[\"jaw_pose\"] = torch.nn.Parameter(torch.zeros(2,3)).to(device)\n",
    "params[\"eye_pose\"] = torch.nn.Parameter(torch.zeros(2,6)).to(device)\n",
    "params[\"transl\"] = torch.nn.Parameter(torch.tensor([[0.043, -0.003, -0.528],[0.043, -0.003, -0.528]])).to(device)\n",
    "params[\"scale\"] = torch.nn.Parameter(torch.ones(2,1)).to(device)\n",
    "\n",
    "# params[\"shape_params\"] = torch.nn.Parameter(torch.zeros(1,100)).to(device)\n",
    "# params[\"expression_params\"] = torch.nn.Parameter(torch.zeros(1,50)).to(device)\n",
    "# params[\"global_pose\"] = torch.nn.Parameter(torch.tensor([[0.08, -0.24, -0.02]])).to(device)\n",
    "# params[\"neck_pose\"] = torch.nn.Parameter(torch.zeros(1,3)).to(device)\n",
    "# params[\"jaw_pose\"] = torch.nn.Parameter(torch.zeros(1,3)).to(device)\n",
    "# params[\"eye_pose\"] = torch.nn.Parameter(torch.zeros(1,6)).to(device)\n",
    "# params[\"transl\"] = torch.nn.Parameter(torch.tensor([[0.043, -0.003, -0.528]])).to(device)\n",
    "# params[\"scale\"] = torch.nn.Parameter(torch.ones(1,1)).to(device)\n",
    "\n",
    "optimizer = GaussNewton(lin_solver=PytorchSolver())\n",
    "param_groups = [{\"params\": [v], \"p_name\": k} for k, v in params.items()]\n",
    "optimizer.set_param_groups(param_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate(\n",
    "    vertices_idx: torch.Tensor,\n",
    "    bary_coords: torch.Tensor,\n",
    "    attributes: torch.Tensor,\n",
    "):\n",
    "    # access the vertex attributes\n",
    "    B, H, W, _ = vertices_idx.shape  # (B, H, W, 3)\n",
    "    _, V, D = attributes.shape  # (B, V, D)\n",
    "\n",
    "    # Flatten the vertices_idx and bary_coords to reduce unnecessary operations\n",
    "    flat_vertices_idx = vertices_idx.view(B, -1)  # (B, H*W*3)\n",
    "\n",
    "    # Efficiently gather the vertex attributes in one step\n",
    "    vertex_attributes = attributes.gather(\n",
    "        1, flat_vertices_idx.unsqueeze(-1).expand(-1, -1, D)\n",
    "    )  # (B, H*W*3, D)\n",
    "\n",
    "    # Reshape gathered attributes to (B, H, W, 3, D) directly\n",
    "    vertex_attributes = vertex_attributes.view(B, H, W, 3, D)\n",
    "\n",
    "    # Perform the weighted sum using barycentric coordinates\n",
    "    bary_coords = bary_coords.unsqueeze(-1)  # (B, H, W, 3, 1)\n",
    "    attributes = (bary_coords * vertex_attributes).sum(dim=-2)  # (B, H, W, D)\n",
    "\n",
    "    return attributes\n",
    "\n",
    "\n",
    "def mask_interpolate(\n",
    "    vertices_idx: torch.Tensor,  # (B, H, W, 3)\n",
    "    bary_coords: torch.Tensor,  # (B, H, W, 3)\n",
    "    attributes: torch.Tensor,  # (B, V, D)\n",
    "    mask: torch.Tensor,  # (B, H, W, 3)\n",
    "):\n",
    "    # access the vertex attributes\n",
    "    B, V, D = attributes.shape  # (B, V, D)\n",
    "    vertices_offset = V * torch.arange(B, device=vertices_idx.device)\n",
    "    v_idx = vertices_idx.clone()\n",
    "    v_idx += vertices_offset.view(B, 1, 1, 1)  # (B, H, W, 3)\n",
    "    v_idx = v_idx[mask]  # (C, 3)\n",
    "    vertex_attribute = attributes.reshape(-1, D)[v_idx]  # (C, 3, D)\n",
    "\n",
    "    bary_coords = bary_coords[mask].unsqueeze(-1)  # (C, 3, 1)\n",
    "    attributes = (bary_coords * vertex_attribute).sum(-2)  # (B, H, W, D)\n",
    "    return attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd.functional import jacobian\n",
    "from torch.func import jacrev, vmap, jacfwd\n",
    "import torch.utils.benchmark as benchmark\n",
    "from lib.utils.mesh import vertex_normals\n",
    "\n",
    "\n",
    "def jacobian():\n",
    "    m_out = flame.model_step(\n",
    "        global_pose=params[\"global_pose\"],\n",
    "        transl=params[\"transl\"],\n",
    "        neck_pose=params[\"neck_pose\"],\n",
    "        expression_params=params[\"expression_params\"],\n",
    "        shape_params=params[\"shape_params\"],\n",
    "    )\n",
    "\n",
    "    r_out = flame.render_step(\n",
    "        renderer=renderer,\n",
    "        vertices=m_out[\"vertices\"],\n",
    "    )\n",
    "    c_out = flame.correspondence_step(\n",
    "        s_point=batch[\"point\"],\n",
    "        s_mask=batch[\"mask\"],\n",
    "        s_normal=batch[\"normal\"],\n",
    "        t_point=r_out[\"point\"],\n",
    "        t_mask=r_out[\"r_mask\"],\n",
    "        t_normal=r_out[\"normal\"],\n",
    "    )\n",
    "    mask = c_out[\"mask\"]\n",
    "\n",
    "    def closure(global_pose, transl, neck_pose, scale, expression_params, shape_params):\n",
    "        m_out = flame.model_step(\n",
    "            global_pose=global_pose,\n",
    "            transl=transl,\n",
    "            expression_params=expression_params,\n",
    "            scale=scale,\n",
    "            neck_pose=neck_pose,\n",
    "            shape_params=shape_params,\n",
    "        )\n",
    "        t_point = interpolate(\n",
    "            vertices_idx=r_out[\"vertices_idx\"],\n",
    "            bary_coords=r_out[\"bary_coords\"],\n",
    "            attributes=m_out[\"vertices\"],\n",
    "        )\n",
    "        t_point = t_point[mask]\n",
    "        s_point = batch[\"point\"][mask]\n",
    "        t_normal = r_out[\"normal\"][mask]\n",
    "        point2plane = ((s_point - t_point) * t_normal).sum(-1)  # (C)\n",
    "        regularization = expression_params.flatten()\n",
    "        F = torch.cat([point2plane, regularization])\n",
    "        return F, F\n",
    "\n",
    "    jacobian_fn = jacfwd(closure, has_aux=True, argnums=(0,1,2,3,4,5))\n",
    "    jacobian, F = jacobian_fn(\n",
    "        params[\"global_pose\"],\n",
    "        params[\"transl\"],\n",
    "        params[\"neck_pose\"],\n",
    "        params[\"scale\"],\n",
    "        params[\"expression_params\"],\n",
    "        params[\"shape_params\"],\n",
    "    )\n",
    "    J = torch.cat([j.flatten(-2) for j in jacobian], dim=-1)  # (M, N)\n",
    "    \n",
    "    # solve for delta\n",
    "    H = 2 * J.T @ J\n",
    "    grad_f = J.T @ F\n",
    "    delta = torch.linalg.solve(H, grad_f)\n",
    "    return delta\n",
    "\n",
    "t0 = benchmark.Timer(\n",
    "    stmt=\"jacobian()\",\n",
    "    setup=\"from __main__ import jacobian\",\n",
    "    globals=globals(),\n",
    ")\n",
    "print(t0.timeit(200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_out = flame.model_step(\n",
    "    global_pose=params[\"global_pose\"],\n",
    "    transl=params[\"transl\"],\n",
    "    neck_pose=params[\"neck_pose\"],\n",
    "    expression_params=params[\"expression_params\"],\n",
    "    shape_params=params[\"shape_params\"],\n",
    ")\n",
    "\n",
    "r_out = flame.render_step(\n",
    "    renderer=renderer,\n",
    "    vertices=m_out[\"vertices\"],\n",
    ")\n",
    "c_out = flame.correspondence_step(\n",
    "    s_point=batch[\"point\"],\n",
    "    s_mask=batch[\"mask\"],\n",
    "    s_normal=batch[\"normal\"],\n",
    "    t_point=r_out[\"point\"],\n",
    "    t_mask=r_out[\"r_mask\"],\n",
    "    t_normal=r_out[\"normal\"],\n",
    ")\n",
    "mask = c_out[\"mask\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_mask = batch[\"mask\"]\n",
    "t_mask = r_out[\"r_mask\"]\n",
    "bary_coords = r_out[\"bary_coords\"].clone()\n",
    "bary_coords[~mask] = torch.nan \n",
    "t_point = interpolate(\n",
    "    vertices_idx=r_out[\"vertices_idx\"],\n",
    "    bary_coords=bary_coords,\n",
    "    attributes=m_out[\"vertices\"],\n",
    ")\n",
    "\n",
    "B, H, W, C = t_point.shape\n",
    "x = torch.linspace(-1, 1, steps=W, device=t_point.device)\n",
    "x += torch.rand_like(x) * 0.01\n",
    "y = torch.linspace(-1, 1, steps=H, device=t_point.device)\n",
    "y += torch.rand_like(y) * 0.01\n",
    "y, x = torch.meshgrid(y, x, indexing=\"ij\")\n",
    "grid = torch.stack([y, x], dim=-1).expand(B, H, W, 2)\n",
    "\n",
    "t_point = batch[\"point\"].permute(0, 3, 1, 2)\n",
    "samples = torch.nn.functional.grid_sample(\n",
    "    input=t_point,\n",
    "    grid=grid,\n",
    "    mode=\"bilinear\",\n",
    "    align_corners=False,\n",
    "    padding_mode=\"zeros\",\n",
    ")\n",
    "samples = samples.permute(0, 2, 3, 1)\n",
    "mask = ~torch.isnan(samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optical_flow(\n",
    "    s_point: torch.Tensor,\n",
    "    t_point: torch.Tensor,\n",
    "):\n",
    "    B, H, W, C = s_point.shape\n",
    "    x = torch.linspace(-1, 1, steps=W, device=s_point.device)\n",
    "    x = torch.rand_like(x) * 0.01\n",
    "    y = torch.linspace(-1, 1, steps=H, device=s_point.device)\n",
    "    y = torch.rand_like(y) * 0.01\n",
    "    y, x = torch.meshgrid(y, x, indexing=\"ij\")\n",
    "    delta = torch.stack([y, x], dim=-1).expand(B, H, W, 2)\n",
    "    return delta\n",
    "\n",
    "\n",
    "def weight():\n",
    "    x = torch.linspace(-1, 1, steps=W, device=t_point.device)\n",
    "    x = torch.rand_like(x) * 0.01\n",
    "    y = torch.linspace(-1, 1, steps=H, device=t_point.device)\n",
    "    y = torch.rand_like(y) * 0.01\n",
    "    y, x = torch.meshgrid(y, x, indexing=\"ij\")\n",
    "    return x.expand(B, H, W)\n",
    "\n",
    "def correspondences(\n",
    "    s_delta: torch.Tensor,\n",
    "    s_mask: torch.Tensor,\n",
    "    t_value: torch.Tensor,\n",
    "    t_mask: torch.Tensor,\n",
    "):\n",
    "    B, H, W, C = t_value.shape\n",
    "\n",
    "    # create the pixel grid\n",
    "    x = torch.linspace(-1, 1, steps=W, device=t_point.device)\n",
    "    y = torch.linspace(-1, 1, steps=H, device=t_point.device)\n",
    "    y, x = torch.meshgrid(y, x, indexing=\"ij\")\n",
    "    grid = torch.stack([y, x], dim=-1).expand(B, H, W, 2)\n",
    "\n",
    "    # add the optical flow delta between (-1, 1)\n",
    "    grid = grid + s_delta\n",
    "\n",
    "    # the values that are not in the mask needs to be marked diry for interpolation\n",
    "    # we need to prepare for bilinear interpolation\n",
    "    value = t_value.clone()\n",
    "    value[~t_mask] = torch.nan \n",
    "    value = value.permute(0, 3, 1, 2)\n",
    "\n",
    "    samples = torch.nn.functional.grid_sample(\n",
    "        input=value,\n",
    "        grid=grid,\n",
    "        mode=\"bilinear\",\n",
    "        align_corners=False,\n",
    "        padding_mode=\"zeros\",\n",
    "    )\n",
    "    samples = samples.permute(0, 2, 3, 1)\n",
    "    \n",
    "    # update the target mask\n",
    "    t_new_mask = ~torch.isnan(samples[..., 0])\n",
    "\n",
    "    # compute the mask, where the source points found a correspondence point\n",
    "    mask = t_new_mask & s_mask \n",
    "    values = samples.nan_to_num(0.0)\n",
    "\n",
    "    return mask, values\n",
    "\n",
    "s_delta = optical_flow(s_point=batch[\"point\"], t_point=r_out[\"point\"])\n",
    "s_mask = batch[\"mask\"]\n",
    "t_mask = r_out[\"r_mask\"]\n",
    "t_value = interpolate(\n",
    "    vertices_idx=r_out[\"vertices_idx\"],\n",
    "    bary_coords=r_out[\"bary_coords\"],\n",
    "    attributes=m_out[\"vertices\"],\n",
    ")\n",
    "m, v = correspondences(\n",
    "    s_delta = s_delta,\n",
    "    s_mask = s_mask,\n",
    "    t_value = t_value,\n",
    "    t_mask = t_mask,\n",
    ")\n",
    "s_mask.sum(), t_mask.sum(), m.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B, H, W, C = t_point.shape\n",
    "\n",
    "x = torch.linspace(-1, 1, steps=W, device=t_point.device)\n",
    "x += torch.rand_like(x) * 0.01\n",
    "y = torch.linspace(-1, 1, steps=H, device=t_point.device)\n",
    "y += torch.rand_like(y) * 0.01\n",
    "y, x = torch.meshgrid(y, x, indexing=\"ij\")\n",
    "grid = torch.stack([y, x], dim=-1).expand(B, H, W, 2)\n",
    "\n",
    "t_point = batch[\"mask\"].unsqueeze(-1).permute(0, 3, 1, 2)\n",
    "samples = torch.nn.functional.grid_sample(\n",
    "    input=t_point,\n",
    "    grid=grid,\n",
    "    mode=\"bilinear\",\n",
    "    align_corners=False,\n",
    "    padding_mode=\"zeros\",\n",
    ")\n",
    "samples = samples.permute(0, 2, 3, 1)\n",
    "mask = ~torch.isnan(samples)\n",
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def foo():\n",
    "    batch[\"point\"][mask]\n",
    "\n",
    "t0 = benchmark.Timer(\n",
    "    stmt=\"foo()\",\n",
    "    setup=\"from __main__ import foo\",\n",
    "    globals=globals(),\n",
    ")\n",
    "print(t0.timeit(1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate(\n",
    "    vertices_idx: torch.Tensor,\n",
    "    bary_coords: torch.Tensor,\n",
    "    attributes: torch.Tensor,\n",
    "):\n",
    "    B, H, W, _ = vertices_idx.shape  # (B, H, W, 3)\n",
    "    _, V, D = attributes.shape  # (B, V, D)\n",
    "\n",
    "    # Flatten the vertices_idx to use it for indexing attributes directly\n",
    "    flat_vertices_idx = vertices_idx.view(B, -1)  # (B, H*W*3)\n",
    "    \n",
    "    # Efficiently gather the vertex attributes\n",
    "    vertex_attributes = attributes.gather(1, flat_vertices_idx.unsqueeze(-1).expand(-1, -1, D))  # (B, H*W*3, D)\n",
    "    \n",
    "    # Reshape to get the desired shape (B, H, W, 3, D)\n",
    "    vertex_attributes = vertex_attributes.view(B, H, W, 3, D)\n",
    "\n",
    "    # Add a dimension to bary_coords for broadcasting\n",
    "    bary_coords = bary_coords.unsqueeze(-1)  # (B, H, W, 3, 1)\n",
    "    \n",
    "    # Perform the weighted sum\n",
    "    interpolated_attributes = (bary_coords * vertex_attributes).sum(dim=-2)  # (B, H, W, D)\n",
    "    \n",
    "    return interpolated_attributes\n",
    "\n",
    "def interpolate1(\n",
    "    vertices_idx: torch.Tensor,\n",
    "    bary_coords: torch.Tensor,\n",
    "    attributes: torch.Tensor,\n",
    "):\n",
    "    # access the vertex attributes\n",
    "    B, H, W, _ = vertices_idx.shape  # (B, H, W, 3)\n",
    "    _, _, D = attributes.shape  # (B, V, D)\n",
    "    v_idx = vertices_idx.clone()\n",
    "    v_idx = v_idx.reshape(B, -1)  # (B, *)\n",
    "    b_idx = torch.arange(v_idx.size(0), device=v_idx.device).unsqueeze(1)\n",
    "    vertex_attribute = attributes[b_idx, v_idx]  # (B, *, D)\n",
    "    vertex_attribute = vertex_attribute.reshape(B, H, W, 3, D)  # (B, H, W, 3, D)\n",
    "\n",
    "    bary_coords = bary_coords.unsqueeze(-1)  # (B, H, W, 3, 1)\n",
    "    attributes = (bary_coords * vertex_attribute).sum(-2)  # (B, H, W, D)\n",
    "    return attributes\n",
    "\n",
    "def interpolate2(\n",
    "    vertices_idx: torch.Tensor,\n",
    "    bary_coords: torch.Tensor,\n",
    "    attributes: torch.Tensor,\n",
    "):\n",
    "    B, H, W, _ = vertices_idx.shape  # (B, H, W, 3)\n",
    "    _, V, D = attributes.shape  # (B, V, D)\n",
    "\n",
    "    # Flatten the vertices_idx and bary_coords to reduce unnecessary operations\n",
    "    flat_vertices_idx = vertices_idx.view(B, -1)  # (B, H*W*3)\n",
    "\n",
    "    # Efficiently gather the vertex attributes in one step\n",
    "    vertex_attributes = attributes.gather(1, flat_vertices_idx.unsqueeze(-1).expand(-1, -1, D))  # (B, H*W*3, D)\n",
    "\n",
    "    # Reshape gathered attributes to (B, H, W, 3, D) directly\n",
    "    vertex_attributes = vertex_attributes.view(B, H, W, 3, D)\n",
    "\n",
    "    # Perform the weighted sum using barycentric coordinates\n",
    "    interpolated_attributes = (bary_coords.unsqueeze(-1) * vertex_attributes).sum(dim=-2)  # (B, H, W, D)\n",
    "\n",
    "    return interpolated_attributes\n",
    "\n",
    "def mask_interpolate(\n",
    "    vertices_idx: torch.Tensor,  # (B, H, W, 3)\n",
    "    bary_coords: torch.Tensor,  # (B, H, W, 3)\n",
    "    attributes: torch.Tensor,  # (B, V, D)\n",
    "    mask: torch.Tensor,  # (B, H, W, 3)\n",
    "):\n",
    "    # access the vertex attributes\n",
    "    B, V, D = attributes.shape  # (B, V, D)\n",
    "    vertices_offset = V * torch.arange(B, device=vertices_idx.device)\n",
    "    v_idx = vertices_idx.clone()\n",
    "    v_idx += vertices_offset.view(B, 1, 1, 1)  # (B, H, W, 3)\n",
    "    v_idx = v_idx[mask]  # (C, 3)\n",
    "    vertex_attribute = attributes.reshape(-1, D)[v_idx]  # (C, 3, D)\n",
    "\n",
    "    bary_coords = bary_coords[mask].unsqueeze(-1)  # (C, 3, 1)\n",
    "    attributes = (bary_coords * vertex_attribute).sum(-2)  # (B, H, W, D)\n",
    "    return attributes\n",
    "\n",
    "def foo():\n",
    "    interpolate2(\n",
    "        vertices_idx=r_out[\"vertices_idx\"],\n",
    "        bary_coords=r_out[\"bary_coords\"],\n",
    "        attributes=m_out[\"vertices\"],\n",
    "    )[mask]\n",
    "\n",
    "# def foo():\n",
    "#     mask_interpolate(\n",
    "#         vertices_idx=r_out[\"vertices_idx\"],\n",
    "#         bary_coords=r_out[\"bary_coords\"],\n",
    "#         attributes=m_out[\"vertices\"],\n",
    "#         mask=mask\n",
    "#     )\n",
    "\n",
    "t0 = benchmark.Timer(\n",
    "    stmt=\"foo()\",\n",
    "    setup=\"from __main__ import foo\",\n",
    "    globals=globals(),\n",
    ")\n",
    "print(t0.timeit(1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = r_out[\"r_mask\"]\n",
    "bary_coords = r_out[\"bary_coords\"]\n",
    "vertices_idx = r_out[\"vertices_idx\"]\n",
    "attibutes = m_out[\"vertices\"]\n",
    "\n",
    "B, H, W, C = bary_coords.shape\n",
    "coords = torch.tensor([[[121.7, 42.3], [122.7, 45.3], [121.7, 42.3]]] * B).to(\"cuda\")  # Example batch of coordinates\n",
    "_, N, _ = coords.shape\n",
    "\n",
    "# Separate the coordinates into x and y parts\n",
    "x, y = coords[..., 0], coords[..., 1]\n",
    "\n",
    "# Get the integer part of the coordinates\n",
    "x0 = torch.floor(x).long()\n",
    "x1 = x0 + 1\n",
    "y0 = torch.floor(y).long()\n",
    "y1 = y0 + 1\n",
    "\n",
    "x0 = torch.clamp(x0, 0, W - 1)  # (B, N, 3)\n",
    "x1 = torch.clamp(x1, 0, W - 1)  # (B, N, 3)\n",
    "y0 = torch.clamp(y0, 0, H - 1)  # (B, N, 3)\n",
    "y1 = torch.clamp(y1, 0, H - 1)  # (B, N, 3)\n",
    "\n",
    "batch_indices = torch.arange(B, dtype=torch.long).view(-1, 1, 1).expand(-1, N, -1).to(\"cuda\")\n",
    "\n",
    "# Gather pixel values at the corners\n",
    "Ia = bary_coords[batch_indices, y0.unsqueeze(-1), x0.unsqueeze(-1)].squeeze(2)  # top-left\n",
    "Ib = bary_coords[batch_indices, y1.unsqueeze(-1), x0.unsqueeze(-1)].squeeze(2)  # bottom-left\n",
    "Ic = bary_coords[batch_indices, y0.unsqueeze(-1), x1.unsqueeze(-1)].squeeze(2)  # top-right\n",
    "Id = bary_coords[batch_indices, y1.unsqueeze(-1), x1.unsqueeze(-1)].squeeze(2)  # bottom-right\n",
    "\n",
    "# Get the fractional part of the coordinates\n",
    "wa = (x1.float() - x) * (y1.float() - y)\n",
    "wb = (x1.float() - x) * (y - y0.float())\n",
    "wc = (x - x0.float()) * (y1.float() - y)\n",
    "wd = (x - x0.float()) * (y - y0.float())\n",
    "\n",
    "interpolated_values = (wa.unsqueeze(-1) * Ia + \n",
    "                        wb.unsqueeze(-1) * Ib + \n",
    "                        wc.unsqueeze(-1) * Ic + \n",
    "                        wd.unsqueeze(-1) * Id)\n",
    "\n",
    "Ia = vertices_idx[batch_indices, y0.unsqueeze(-1), x0.unsqueeze(-1)].squeeze(2)  # top-left\n",
    "Ib = vertices_idx[batch_indices, y1.unsqueeze(-1), x0.unsqueeze(-1)].squeeze(2)  # bottom-left\n",
    "Ic = vertices_idx[batch_indices, y0.unsqueeze(-1), x1.unsqueeze(-1)].squeeze(2)  # top-right\n",
    "Id = vertices_idx[batch_indices, y1.unsqueeze(-1), x1.unsqueeze(-1)].squeeze(2)  # bottom-right\n",
    "\n",
    "# batch_indices.shape, x0.shape\n",
    "# bary_coords[torch.tensor([0]).view(1, 1, 1), torch.tensor([0, 1]).view(1, 2, 1), torch.tensor([0, 1, 3]).view(1, 1, 3)].shape\n",
    "# bary_coords[torch.tensor([0, 1]).view(2, 1, 1), y0].shape\n",
    "# Ia = bary_coords[batch_indices, y0.unsqueeze(-1), x0.unsqueeze(-1)].squeeze(2)  # top-left\n",
    "# Ia.shape\n",
    "Ia, Ib, Ic, Id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = torch.cat([\n",
    "    params[\"global_pose\"],\n",
    "    params[\"transl\"],\n",
    "    params[\"expression_params\"],\n",
    "    params[\"neck_pose\"],\n",
    "    # params[\"shape_params\"]\n",
    "]).expand(1, -1)\n",
    "\n",
    "def jacobian():\n",
    "    def closure(p):\n",
    "        m_out = flame.model_step(\n",
    "            global_pose=p[0:3],\n",
    "            transl=p[3:6],\n",
    "            neck_pose=p[6:9],\n",
    "            expression_params=p[9:59],\n",
    "            shape_params=p[59:159],\n",
    "        )\n",
    "        s_point = batch[\"point\"][mask]\n",
    "        t_normal = r_out[\"normal\"][mask]\n",
    "        t_point = renderer.mask_interpolate(\n",
    "            vertices_idx=r_out[\"vertices_idx\"],\n",
    "            bary_coords=r_out[\"bary_coords\"],\n",
    "            attributes=m_out[\"vertices\"],\n",
    "            mask=c_out[\"mask\"],\n",
    "        )\n",
    "        F = ((s_point - t_point) * t_normal).sum(-1)  # (C)\n",
    "        J = torch.cat([F, p[9:59].flatten()])\n",
    "        return J, F\n",
    "\n",
    "    J, F = vmap(jacfwd(closure, has_aux=True))(p)\n",
    "    # J, F = jacfwd(closure, has_aux=True, argnums=(0, 1, 2, 3, 4))(\n",
    "    #     params[\"global_pose\"],\n",
    "    #     params[\"transl\"],\n",
    "    #     params[\"neck_pose\"],\n",
    "    #     params[\"expression_params\"][0],\n",
    "    #     params[\"shape_params\"],\n",
    "    # )\n",
    "    # J = torch.cat([j.flatten(-2) for j in J], dim=-1)  # (M, N)\n",
    "\n",
    "t0 = benchmark.Timer(\n",
    "    stmt=\"jacobian()\",\n",
    "    setup=\"from __main__ import jacobian\",\n",
    "    globals=globals(),\n",
    ")\n",
    "print(t0.timeit(200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 17.88 (6 + 40)\n",
    "# 12.77 (6 + 20)\n",
    "17.88 / 46, 12.77 / 26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "s = time.time()\n",
    "m_out = flame.model_step()\n",
    "(time.time() - s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(batch[\"color\"][0].detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def closure(\n",
    "#     shape_params,\n",
    "#     expression_params,\n",
    "#     global_pose,\n",
    "#     neck_pose,\n",
    "#     jaw_pose,\n",
    "#     eye_pose,\n",
    "#     transl,\n",
    "#     scale,\n",
    "# ):\n",
    "flame(\n",
    "    shape_params=params[\"shape_params\"],\n",
    "    expression_params=params[\"expression_params\"],\n",
    "    global_pose=params[\"global_pose\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.data.width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flame.default_shape_params.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "shape_params = torch.rand((1, 100)).to(\"cuda\")\n",
    "expression_params = torch.rand((32, 50)).to(\"cuda\")\n",
    "flame(shape_params=shape_params, expression_params=expression_params).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_params.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "guided",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
