{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flame\n",
    "\n",
    "In order to download the models we need to look at: https://flame.is.tue.mpg.de/download.php\n",
    "This could be usefull if onw want's to look how to load the FLAME model from the SMPL loader: https://github.com/Rubikplayer/flame-fitting/blob/master/smpl_webuser/serialization.py#L117\n",
    "Useful utils if one needs to transform the chumpy format into nupy or torch: https://github.com/vchoutas/smplx/blob/main/smplx/utils.py\n",
    "\n",
    "NOTE: That if one want't to unpickle old python=2.x numpy code, we need to use the encoding=\"latin1\". For more information please refere to: https://docs.python.org/3/library/pickle.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from lib.utils.loader import load_flame\n",
    "from lib.model.flame import FLAME\n",
    "\n",
    "# https://github.com/soubhiksanyal/FLAME_PyTorch/blob/master/flame_pytorch/flame.py\n",
    "data_dir = \"/Users/robinborth/Code/GuidedResearch/data/dphm_christoph_mouthmove\"\n",
    "flame_dir = \"/Users/robinborth/Code/GuidedResearch/checkpoints/flame2023\"\n",
    "flame_dict = load_flame(flame_dir)\n",
    "flame_model = FLAME(flame_dir=flame_dir, data_dir=data_dir)\n",
    "print(\"FLAME keys:\")\n",
    "print(list(flame_dict.keys()))\n",
    "print()\n",
    "\n",
    "# This is the linear blend skinning (LBS) with corrective blendshapes with N=5023 and\n",
    "# K=4 joint (neck, jaw, and eyeballs (left, right))\n",
    "bs_style = flame_dict[\"bs_style\"]\n",
    "print(\"bs_style:\", bs_style)\n",
    "bs_type = flame_dict[\"bs_type\"]\n",
    "print(\"bs_type:\", bs_type)\n",
    "\n",
    "# this is the template mesh, e.g. T bar in the \"zero pose\"\n",
    "v_template = flame_dict[\"v_template\"]\n",
    "print(\"v_template:\", v_template.shape)\n",
    "for i in range(3):\n",
    "    d = v_template[:, i].max() - v_template[:, i].min()\n",
    "    s = [\"x\", \"y\", \"z\"][i]\n",
    "    print(f\"{s}-delta in meter {d:.2}m\")\n",
    "\n",
    "# those are used in the pytorch flame example\n",
    "f = flame_dict[\"f\"]\n",
    "print(\"f:\", f.shape)\n",
    "\n",
    "# shape (beta); note that the dimension is (5023, 3, 400)\n",
    "# where the first 300 are for the shape params and the last 400 for the expression\n",
    "# params, but the matrix is shared\n",
    "shapedirs = flame_dict[\"shapedirs\"]\n",
    "print(\"shapedirs:\", shapedirs.shape)\n",
    "\n",
    "# pose (theta)\n",
    "posedirs = flame_dict[\"posedirs\"]\n",
    "print(\"posedirs:\", posedirs.shape)\n",
    "\n",
    "# is this the expressions? (psi)\n",
    "weights = flame_dict[\"weights\"]  # lbs := linear blend shapes\n",
    "print(\"weights:\", weights.shape)\n",
    "\n",
    "# Linear smoothed by skinning function(T, J, theta, W).\n",
    "# Blendweights W (KxN) are J_regressor\n",
    "J_regressor = flame_dict[\"J_regressor\"]\n",
    "print(\"J_regressor:\", J_regressor.shape)\n",
    "\n",
    "# J are the joints that the vertices of T are rotated\n",
    "J = flame_dict[\"J\"]\n",
    "print(\"J:\", J.shape)\n",
    "\n",
    "kintree_table = flame_dict[\"kintree_table\"]\n",
    "print(\"kintree_table:\", kintree_table.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Falme Landmarks\n",
    "\n",
    "The landmark file defines the barycentric embedding of 105 points of the Mediapipe mesh in the surface of FLAME.\n",
    "In consists of three arrays: lmk_face_idx, lmk_b_coords, and landmark_indices.\n",
    "\n",
    "- lmk_face_idx contains for every landmark the index of the FLAME triangle which each landmark is embedded into\n",
    "- lmk_b_coords are the barycentric weights for each vertex of the triangles\n",
    "- landmark_indices are the indices of the vertices of the Mediapipe mesh\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.utils.loader import load_static_landmark_embedding\n",
    "\n",
    "flame_landmarks = load_static_landmark_embedding(flame_dir, \"pt\")\n",
    "print(list(flame_landmarks.keys()))\n",
    "print()\n",
    "\n",
    "print(\"lmk_face_idx:\")\n",
    "print(flame_landmarks[\"lm_face_idx\"][:5])\n",
    "print(flame_landmarks[\"lm_face_idx\"].min())\n",
    "print(flame_landmarks[\"lm_face_idx\"].max())\n",
    "print(flame_landmarks[\"lm_face_idx\"].shape)\n",
    "print()\n",
    "\n",
    "print(\"lmk_b_coords:\")\n",
    "print(flame_landmarks[\"lm_bary_coords\"][:5])\n",
    "print(flame_landmarks[\"lm_bary_coords\"].min())\n",
    "print(flame_landmarks[\"lm_bary_coords\"].max())\n",
    "print(flame_landmarks[\"lm_bary_coords\"].shape)\n",
    "print()\n",
    "\n",
    "print(\"landmark_indices:\")\n",
    "print(flame_landmarks[\"lm_mediapipe_idx\"][:5])\n",
    "print(flame_landmarks[\"lm_mediapipe_idx\"].min())\n",
    "print(flame_landmarks[\"lm_mediapipe_idx\"].max())\n",
    "print(flame_landmarks[\"lm_mediapipe_idx\"].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FLAME Mask\n",
    "\n",
    "Dictionary with vertex indices for different masks for the publicly available FLAME head model (https://flame.is.tue.mpg.de/).\n",
    "See the gif for a visualization of all masks.\n",
    "\n",
    "Those are the vertices.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.utils.loader import load_flame_masks\n",
    "import torch\n",
    "\n",
    "flame_masks = load_flame_masks(flame_dir)\n",
    "print(list(flame_masks.keys()))\n",
    "print()\n",
    "\n",
    "print(\"face:\")\n",
    "print(flame_masks[\"face\"][:5])\n",
    "print(flame_masks[\"face\"].min())\n",
    "print(flame_masks[\"face\"].max())\n",
    "print(flame_masks[\"face\"].shape)\n",
    "\n",
    "faces_mask = torch.tensor(flame_masks[\"face\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flame_masks[\"face\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch3D Rasterizer\n",
    "\n",
    "We want to implement our own rasterizer, hence we can look how pytorch metric is doing it:\n",
    "from pytorch3d.renderer.mesh import rasterize_meshes\n",
    "Or we can implmenet it, for reference here:\n",
    "https://www.scratchapixel.com/lessons/3d-basic-rendering/rasterization-practical-implementation/rasterization-stage.html\n",
    "\n",
    "Go over the rasterization:\n",
    "https://www.scratchapixel.com/lessons/3d-basic-rendering/rasterization-practical-implementation/overview-rasterization-algorithm.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.model.flame import FLAME\n",
    "from lib.renderer.renderer import Renderer\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "flame_dir = \"/home/borth/GuidedResearch/checkpoints/flame2023\"\n",
    "data_dir = \"/home/borth/GuidedResearch/data/dphm_christoph_mouthmove\"\n",
    "scale = 0.25\n",
    "flame = FLAME(\n",
    "    flame_dir=flame_dir,\n",
    "    data_dir=data_dir,\n",
    "    image_scale=scale,\n",
    "    image_height=int(1080 * scale),\n",
    "    image_width=int(1920 * scale),\n",
    ")\n",
    "flame.init_params(\n",
    "    global_pose=[torch.pi, 0, 0],\n",
    "    transl=[0.0, 0.27, 0.5],\n",
    ")\n",
    "vertices, landmarks = flame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flame.faces.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.renderer.camera import camera2pixel\n",
    "camera2pixel(landmarks, flame.K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.utils.mesh import weighted_vertex_normals\n",
    "renderer = flame.renderer()\n",
    "normal, mask = renderer.render_normal(vertices, flame.faces)\n",
    "normal_image = renderer.normal_to_normal_image(normal, mask)\n",
    "plt.imshow(normal_image[0].detach().cpu().numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.renderer.camera import camera2pixel\n",
    "# fix\n",
    "K = flame.K\n",
    "vp = camera2pixel(landmarks[0], K[0,0], K[1,1], K[0,2], K[1,2])\n",
    "# vp[flame.faces][:, :, :2]\n",
    "# vp.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.renderer.camera import camera2normal\n",
    "point, mask = renderer.render_point(vertices, flame.faces)\n",
    "n, m = camera2normal(point)\n",
    "normal_image = renderer.normal_to_normal_image(n, m)\n",
    "plt.imshow(normal_image.detach().cpu().numpy()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.utils.loader import load_color\n",
    "\n",
    "color_image = load_color(data_dir=data_dir, idx=0, return_tensor=\"pt\")\n",
    "image = renderer.render_color_image(\n",
    "    vertices, flame_model.faces, color_image, faces_mask, True\n",
    ")\n",
    "plt.imshow(image.detach().cpu().numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal = renderer.render_normal_image(vertices, flame_model.faces, faces_mask)\n",
    "plt.imshow(normal.detach().cpu().numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth = renderer.render_shader_image(vertices, flame_model.faces, faces_mask)\n",
    "plt.imshow(depth.detach().cpu().numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "path = \"/Users/robinborth/Code/GuidedResearch/checkpoints/flame2023_no_jaw/FLAME_texture.npz\"\n",
    "albedo = np.load(path)\n",
    "albedo_faces = albedo[\"vt\"][albedo[\"ft\"]]\n",
    "albedo_map = albedo[\"mean\"].astype(np.uint8)\n",
    "plt.imshow(albedo_map[:, :, ::-1])\n",
    "# albedo_faces.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open3D Point Cloud\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from lib.utils.loader import load_points_3d\n",
    "\n",
    "C = 5023\n",
    "red = [np.array([255, 0, 0], dtype=np.uint8)] * C\n",
    "red = o3d.utility.Vector3dVector(np.stack(red))\n",
    "green = [np.array([0, 255, 0], dtype=np.uint8)] * C\n",
    "green = o3d.utility.Vector3dVector(np.stack(green))\n",
    "blue = [np.array([0, 0, 255], dtype=np.uint8)] * C\n",
    "blue = o3d.utility.Vector3dVector(np.stack(blue))\n",
    "\n",
    "vertices = np.load(\"temp/vertices.npy\")\n",
    "pcd_flame = o3d.geometry.PointCloud()\n",
    "pcd_flame.points = o3d.utility.Vector3dVector(vertices)\n",
    "pcd_flame.colors = blue\n",
    "\n",
    "data_dir = Path(\"/Users/robinborth/Code/GuidedResearch/data/dphm_christoph_mouthmove\")\n",
    "points = load_points_3d(data_dir=data_dir, idx=0)\n",
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(points)\n",
    "pcd.colors = red\n",
    "\n",
    "o3d.visualization.draw_plotly([pcd, pcd_flame])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Albedo Diffuse\n",
    "\n",
    "This describes how to convert from BFM to FLAME:\n",
    "https://github.com/TimoBolkart/BFM_to_FLAME\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "path = \"/Users/robinborth/Code/GuidedResearch/checkpoints/flame2023_no_jaw/albedoModel2020_FLAME_albedoPart.npz\"\n",
    "albedo = np.load(path)\n",
    "print(list(albedo.keys()))\n",
    "print(f\"{albedo['vt'].shape=}\")\n",
    "print(f\"{albedo['vt'].min()=}\")\n",
    "print(f\"{albedo['vt'].max()=}\")\n",
    "print(f\"{albedo['ft'].shape=}\")\n",
    "print(f\"{albedo['ft'].min()=}\")\n",
    "print(f\"{albedo['ft'].max()=}\")\n",
    "print(f\"{albedo['specPC'].shape=}\")\n",
    "print(f\"{albedo['PC'].shape=}\")\n",
    "print(f\"{albedo['specMU'].shape=}\")\n",
    "print(f\"{albedo['MU'].shape=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "albedo[\"ft\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "albedo[\"vt\"].shape[0] - 5023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(albedo[\"MU\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other Albedo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/Users/robinborth/Code/GuidedResearch/checkpoints/flame2023_no_jaw/FLAME_texture.npz\"\n",
    "albedo = np.load(path)\n",
    "albedo_faces = albedo[\"vt\"][albedo[\"ft\"]]\n",
    "albedo_map = albedo[\"mean\"]\n",
    "\n",
    "list(albedo.keys())\n",
    "print(f\"{albedo['vt'].shape=}\")\n",
    "print(f\"{albedo['vt'].min()=}\")\n",
    "print(f\"{albedo['vt'].max()=}\")\n",
    "print(f\"{albedo['ft'].shape=}\")\n",
    "print(f\"{albedo['ft'].min()=}\")\n",
    "print(f\"{albedo['ft'].max()=}\")\n",
    "print(f\"{albedo['tex_dir'].shape=}\")\n",
    "print(f\"{albedo['mean'].shape=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(albedo[\"mean\"].astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flame_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "path = \"/Users/robinborth/Code/GuidedResearch/checkpoints/flame2023/FLAME_albedo_from_BFM.npz\"\n",
    "albedo = np.load(path)\n",
    "print(list(albedo.keys()))\n",
    "albedo[\"PC\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch3d.io import load_obj\n",
    "\n",
    "verts, faces, aux = load_obj(\n",
    "    \"/Users/robinborth/Code/GuidedResearch/checkpoints/flame2023/head_template.obj\"\n",
    ")\n",
    "aux.verts_uvs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faces.verts_idx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verts_uvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/Users/robinborth/Code/GuidedResearch/logs/optimize/runs/2024-04-25_17-49-55\"\n",
    "i = 650\n",
    "vertices = np.load(f\"{path}/pcd_vertices/000_{i:05}.npz\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "guided",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
