{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import hydra\n",
    "import torch\n",
    "from lib.utils.config import load_config\n",
    "from lib.optimizer.framework import NeuralOptimizer\n",
    "from lib.data.loader import load_intrinsics\n",
    "from lib.data.loader import load_intrinsics\n",
    "from lib.rasterizer import Rasterizer\n",
    "from lib.renderer.renderer import Renderer\n",
    "from lib.renderer.camera import Camera\n",
    "from lib.utils.visualize import visualize_point2plane_error\n",
    "import matplotlib.pyplot as plt\n",
    "from lib.utils.visualize import visualize_merged\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "\n",
    "def path_to_abblation(path):\n",
    "    return \"_\".join(path.split(\"/\")[-3].split(\"_\")[1:])\n",
    "\n",
    "\n",
    "def draw_and_save_color(dataset, idx, path):\n",
    "    _path = f\"/home/borth/GuidedResearch/data/dphm_kinect/{dataset}/color/{idx:05}.png\"\n",
    "    img = Image.open(_path)\n",
    "    img.save(path)\n",
    "    # plt.imshow(img)\n",
    "    # plt.axis(\"off\")  # Hide axes\n",
    "    # plt.show()\n",
    "\n",
    "\n",
    "def draw_and_save_weight(flame, renderer, out, path):\n",
    "    renderer.update(1)\n",
    "    mask = flame.render(renderer, out[\"params\"])[\"mask\"][0]\n",
    "    renderer.update(8)\n",
    "\n",
    "    # weight inference\n",
    "    weights = out[\"optim_weights\"][-1]\n",
    "    weights = F.interpolate(\n",
    "        weights.unsqueeze(0), scale_factor=8, mode=\"bilinear\", align_corners=False\n",
    "    )\n",
    "    weights = weights.detach()[0][0]\n",
    "    weights[~mask] = 0.0\n",
    "\n",
    "    plt.figure(figsize=(19.2, 10.8), dpi=100)  # Full HD size\n",
    "    plt.imshow(weights.cpu().numpy())\n",
    "    plt.axis(\"off\")  # Hide axes\n",
    "    plt.savefig(path, bbox_inches=\"tight\", pad_inches=0)  # Save without padding\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def draw_and_save_overlay(optimizer, renderer, params, dataset, idx, path):\n",
    "    _path = f\"/home/borth/GuidedResearch/data/dphm_kinect/{dataset}/color/{idx:05}.png\"\n",
    "    color = torch.tensor(np.asarray(Image.open(_path))).unsqueeze(0).to(\"cuda\")\n",
    "    renderer.update(scale=1)\n",
    "    out = optimizer.flame.render(renderer, params)\n",
    "    renderer.update(scale=8)\n",
    "    img = visualize_merged(\n",
    "        s_color=color,\n",
    "        t_color=out[\"color\"],\n",
    "        t_mask=out[\"mask\"],\n",
    "    )\n",
    "    img = img[0].detach().cpu().numpy()\n",
    "    Image.fromarray(img).save(path)\n",
    "    # plt.imshow(img)\n",
    "    # plt.axis(\"off\")  # Hide axes\n",
    "    # plt.show()\n",
    "\n",
    "\n",
    "def draw_and_save_normal(dataset, idx, path):\n",
    "    _path = f\"/home/borth/GuidedResearch/data/dphm_kinect/{dataset}/cache/2_normal/{idx:05}.pt\"\n",
    "    normal = torch.load(_path)\n",
    "    _path = f\"/home/borth/GuidedResearch/data/dphm_kinect/{dataset}/cache/2_mask/{idx:05}.pt\"\n",
    "    mask = torch.load(_path)\n",
    "    normal_image = (((normal + 1) / 2) * 255).to(torch.uint8)\n",
    "    normal_image[~mask] = 255\n",
    "    Image.fromarray(normal_image.detach().cpu().numpy()).save(path)\n",
    "    # plt.imshow(normal_image.detach().cpu().numpy())\n",
    "    # plt.axis(\"off\")  # Hide axes\n",
    "    # plt.show()\n",
    "\n",
    "\n",
    "def eval_iterations(\n",
    "    optimizer,\n",
    "    renderer,\n",
    "    dataset,\n",
    "    target_frame_idx,\n",
    "    source_frame_idx,\n",
    "    step_size=0.7,\n",
    "    params=None,\n",
    "    N=2,\n",
    "):\n",
    "    cfg = load_config(\"train\", [\"data=kinect\"])\n",
    "    datamodule = hydra.utils.instantiate(\n",
    "        cfg.data,\n",
    "        renderer=renderer,\n",
    "        val_dataset=dict(\n",
    "            start_frame=target_frame_idx,\n",
    "            end_frame=target_frame_idx + 1,\n",
    "            jump_size=target_frame_idx - source_frame_idx,\n",
    "            datasets=[dataset],\n",
    "        ),\n",
    "    )\n",
    "    datamodule.setup(\"fit\")\n",
    "\n",
    "    optimizer.max_iters = N\n",
    "    optimizer.max_optims = 1\n",
    "    optimizer.step_size = step_size\n",
    "    out = None\n",
    "    batch = None\n",
    "    for i, b in enumerate(datamodule.val_dataloader()):\n",
    "        with torch.no_grad():\n",
    "            batch = optimizer.transfer_batch_to_device(b, \"cuda\", 0)\n",
    "            if params is not None:\n",
    "                batch[\"init_params\"] = params\n",
    "            out = optimizer(batch)\n",
    "    return out, batch\n",
    "\n",
    "\n",
    "def draw_and_save(img, path):\n",
    "    # Display and save the error image\n",
    "    Image.fromarray(img.detach().cpu().numpy()).save(path)\n",
    "    # plt.imshow(img)\n",
    "    # plt.axis(\"off\")  # Hide axes\n",
    "    # plt.show()\n",
    "\n",
    "\n",
    "def load_flame_renderer():\n",
    "    # instanciate similar to training\n",
    "    cfg = load_config(\"train\", [\"data=kinect\"])\n",
    "    K = load_intrinsics(data_dir=cfg.data.intrinsics_dir, return_tensor=\"pt\")\n",
    "    camera = Camera(\n",
    "        K=K,\n",
    "        width=cfg.data.width,\n",
    "        height=cfg.data.height,\n",
    "        near=cfg.data.near,\n",
    "        far=cfg.data.far,\n",
    "        scale=cfg.data.scale,\n",
    "    )\n",
    "    rasterizer = Rasterizer(width=camera.width, height=camera.height)\n",
    "    renderer = Renderer(rasterizer=rasterizer, camera=camera)\n",
    "    flame = hydra.utils.instantiate(cfg.model)\n",
    "    return flame, renderer\n",
    "\n",
    "\n",
    "def render_output(renderer, optimizer, out, batch):\n",
    "    renderer.update(scale=1)\n",
    "    pred_out = optimizer.flame.render(renderer, out[\"params\"])\n",
    "    gt_out = optimizer.flame.render(renderer, batch[\"params\"])\n",
    "    error_map = visualize_point2plane_error(\n",
    "        s_point=gt_out[\"point\"][0],\n",
    "        t_normal=pred_out[\"normal\"][0],\n",
    "        t_point=pred_out[\"point\"][0],\n",
    "        t_mask=pred_out[\"mask\"][0],\n",
    "        max_error=2e-03,  # 2mm\n",
    "    )\n",
    "    renderer.update(scale=8)\n",
    "    color = pred_out[\"color\"][0].detach().cpu()\n",
    "    normal = pred_out[\"normal_image\"][0].detach().cpu()\n",
    "    return color, normal, error_map\n",
    "\n",
    "\n",
    "def render(renderer, optimizer, out, batch):\n",
    "    renderer.update(scale=1)\n",
    "    pred_out = optimizer.flame.render(renderer, out[\"params\"])\n",
    "    gt_out = optimizer.flame.render(renderer, batch[\"params\"])\n",
    "    error_map = visualize_point2plane_error(\n",
    "        s_point=gt_out[\"point\"][0],\n",
    "        t_normal=pred_out[\"normal\"][0],\n",
    "        t_point=pred_out[\"point\"][0],\n",
    "        t_mask=pred_out[\"mask\"][0],\n",
    "        max_error=6e-03,  # 2mm\n",
    "    )\n",
    "    renderer.update(scale=8)\n",
    "    color = pred_out[\"color\"][0].detach().cpu()\n",
    "    return color, error_map\n",
    "\n",
    "\n",
    "def load_neural_optimizer(flame, renderer, path, override=[]):\n",
    "    cfg = load_config(\"train\", [\"data=kinect\"] + override)\n",
    "    correspondence = hydra.utils.instantiate(cfg.correspondence)\n",
    "    weighting = hydra.utils.instantiate(cfg.weighting)\n",
    "    residuals = hydra.utils.instantiate(cfg.residuals)\n",
    "    regularize = hydra.utils.instantiate(cfg.regularize)\n",
    "    neural_optimizer = NeuralOptimizer.load_from_checkpoint(\n",
    "        path,\n",
    "        renderer=renderer,\n",
    "        flame=flame,\n",
    "        correspondence=correspondence,\n",
    "        regularize=regularize,\n",
    "        residuals=residuals,\n",
    "        weighting=weighting,\n",
    "    )\n",
    "    return neural_optimizer\n",
    "\n",
    "\n",
    "def load_icp_optimizer(flame, renderer, overrides):\n",
    "    cfg = load_config(\"train\", [\"data=kinect\", \"optimizer.output_dir=none\"] + overrides)\n",
    "    correspondence = hydra.utils.instantiate(cfg.correspondence)\n",
    "    weighting = hydra.utils.instantiate(cfg.weighting)\n",
    "    residuals = hydra.utils.instantiate(cfg.residuals)\n",
    "    optimizer = hydra.utils.instantiate(cfg.optimizer)\n",
    "    regularize = hydra.utils.instantiate(cfg.regularize)\n",
    "    icp_optimizer = hydra.utils.instantiate(\n",
    "        cfg.framework,\n",
    "        flame=flame,\n",
    "        logger=None,\n",
    "        renderer=renderer,\n",
    "        correspondence=correspondence,\n",
    "        regularize=regularize,\n",
    "        residuals=residuals,\n",
    "        optimizer=optimizer,\n",
    "        weighting=weighting,\n",
    "    )\n",
    "    return icp_optimizer.to(\"cuda\")\n",
    "\n",
    "\n",
    "# setup the datamodule\n",
    "def load_datamodule(renderer, start_frame, end_frame, jump_size=1):\n",
    "    cfg = load_config(\"train\", [\"data=kinect\"])\n",
    "    datamodule = hydra.utils.instantiate(\n",
    "        cfg.data,\n",
    "        renderer=renderer,\n",
    "        val_dataset=dict(\n",
    "            start_frame=start_frame, end_frame=end_frame, jump_size=jump_size\n",
    "        ),\n",
    "    )\n",
    "    datamodule.setup(\"fit\")\n",
    "    return datamodule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "from pathlib import Path\n",
    "from lib.utils.video import create_video\n",
    "\n",
    "# loadings\n",
    "flame, renderer = load_flame_renderer()\n",
    "setup = \"presentation\"\n",
    "\n",
    "ours = \"/home/borth/GuidedResearch/checkpoints/kinect/ours.ckpt\"\n",
    "neural_optimizer = load_neural_optimizer(flame, renderer, ours)\n",
    "\n",
    "override = [\"residuals=face2face_wo_landmarks\", \"regularize=dummy\", \"weighting=dummy\"]\n",
    "icp_optimizer = load_icp_optimizer(flame, renderer, override)\n",
    "\n",
    "optimizers = [\n",
    "    (\"neural\", neural_optimizer),\n",
    "    (\"icp\", icp_optimizer),\n",
    "]\n",
    "\n",
    "settings = [\n",
    "    (\"ali_kocal_mouthmove\", 10, 80),\n",
    "    (\"innocenzo_fulgintl_rotatemouth\", 10, 80),\n",
    "    (\"christoph_mouthmove\", 10, 80),\n",
    "]\n",
    "\n",
    "for (optimizer_name, optimizer) in optimizers:\n",
    "    for (dataset, source_idx, target_idx) in settings:\n",
    "        video_dir = f\"results/{setup}/{dataset}/{optimizer_name}\"\n",
    "        params = None\n",
    "        for idx in tqdm(range(source_idx, target_idx)):\n",
    "            t_idx = idx + 1\n",
    "            s_idx = idx\n",
    "            path = ours\n",
    "            out, batch = eval_iterations(\n",
    "                optimizer,\n",
    "                renderer,\n",
    "                dataset,\n",
    "                t_idx,\n",
    "                s_idx,\n",
    "                params=params,\n",
    "            )\n",
    "            params = out[\"params\"]\n",
    "            color, _, error = render_output(renderer, optimizer, out, batch)\n",
    "            frame_path = f\"{video_dir}/{t_idx:05}.png\"\n",
    "            Path(frame_path).parent.mkdir(exist_ok=True, parents=True)\n",
    "            draw_and_save_overlay(optimizer, renderer, params, dataset, t_idx, frame_path)\n",
    "        \n",
    "            frame_path = f\"results/{setup}/{dataset}/ground_truth/{t_idx:05}.png\"\n",
    "            Path(frame_path).parent.mkdir(exist_ok=True, parents=True)\n",
    "            draw_and_save_overlay(optimizer, renderer, batch[\"params\"], dataset, t_idx, frame_path) \n",
    "            frame_path = f\"results/{setup}/{dataset}/color/{t_idx:05}.png\"\n",
    "            Path(frame_path).parent.mkdir(exist_ok=True, parents=True)\n",
    "            draw_and_save_color(dataset, t_idx, frame_path)\n",
    "            frame_path = f\"results/{setup}/{dataset}/normal/{t_idx:05}.png\"\n",
    "            Path(frame_path).parent.mkdir(exist_ok=True, parents=True)\n",
    "            draw_and_save_normal(dataset, t_idx, frame_path)\n",
    "\n",
    "        video_path = Path(f\"results/{setup}\") / f\"{dataset}_{optimizer_name}.mp4\"\n",
    "        create_video(video_dir=video_dir, video_path=video_path, framerate=16)\n",
    "\n",
    "        video_path = Path(f\"results/{setup}\") / f\"{dataset}_ground_truth.mp4\"\n",
    "        create_video(video_dir=f\"results/{setup}/{dataset}/ground_truth\", video_path=video_path, framerate=16)\n",
    "        video_path = Path(f\"results/{setup}\") / f\"{dataset}_color.mp4\"\n",
    "        create_video(video_dir=f\"results/{setup}/{dataset}/color\", video_path=video_path, framerate=16)\n",
    "        video_path = Path(f\"results/{setup}\") / f\"{dataset}_normal.mp4\"\n",
    "        create_video(video_dir=f\"results/{setup}/{dataset}/normal\", video_path=video_path, framerate=16)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "guided",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
