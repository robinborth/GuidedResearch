# @package _global_

defaults:
  - model: flame 
  - logger: flame_wandb
  - data: synthetic # synthetic, kinect, debug
  - residuals: neural  # face2face, neural 
  - optimizer:  gauss_newton 
  - framework : neural
  - correspondence: projective 
  - weighting: unet # dummy, cnn, unet
  - regularize: mlp # dummy, mlp
  - trainer: deterministic  # default, deterministic
  - callbacks: default
  - hydra: default
  - paths: default
  - _self_

# run setting 
train: True
eval: False
ckpt_path: ???

# base configs
seed: 123
device: cuda
task_name: train
tags: 
  - ${task_name}

# override framework settings
framework:
  max_iters: 3
  lr: 5e-04
  residual_weight: 0.01
  geometric_weight: 0.0
  param_weight: 1.0
  vertices_weight: 5e-02

# override trainer settings
trainer:
  max_epochs: 500  # 400
  accumulate_grad_batches: 64  # 8, 32 
  limit_train_batches: 256
