# @package _global_

defaults:
  - data: linsys
  - callbacks: default
  - model: pcg
  - logger: wandb
  - hydra: default
  - paths: default
  - optional local: default
  - _self_

seed: 123
device: cuda
train: True
eval: True
eval_max_iter: 150 
eval_batch_size: 1024
eval_splits: [train,val]
task_name: pcg_training
tags: 
  - ${task_name}

data:
  dataset_name: linsys  # linsys_pose, linsys
  split: [0.98, 0.01, 0.01]
  batch_size: 256

trainer:
  _target_: lightning.pytorch.trainer.Trainer
  default_root_dir: ${paths.output_dir}
  accelerator: ${device}
  # training
  min_epochs: 1 
  max_epochs: 1000
  # debugging
  check_val_every_n_epoch: 20
  num_sanity_val_steps: 0
  log_every_n_steps: 1

model:
  max_iter: 10
  gradients: backprop
  # optimization
  scheduler:
    _target_: torch.optim.lr_scheduler.ExponentialLR
    _partial_: True
    gamma: 0.999
  monitor: train/loss
  condition_net:
    unknowns: 59  # 6, 59
  optimizer:
    _target_: torch.optim.Adam
    _partial_: True
    lr: 1e-03
  